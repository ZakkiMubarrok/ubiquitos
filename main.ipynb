{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNr3Bf6THCXWi19KnMaIOcW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZakkiMubarrok/ubiquitos/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BR6oL0AFjBsR"
      },
      "outputs": [],
      "source": [
        "# !pip install Pillow\n",
        "# !pip install torch torchvision\n",
        "# !pip install git+https://github.com/facebookresearch/detectron2.git\n",
        "\n",
        "\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = r'/content/dataset/mentah'\n",
        "\n",
        "for file in os.listdir(path):\n",
        "    if not file.endswith(\".jpg\"):\n",
        "        img = Image.open(f\"{path}/{file}\")\n",
        "        file_name, file_ext = os.path.splitext(file)\n",
        "        if img.mode != 'RGB':\n",
        "            img = img.convert('RGB')\n",
        "        img.save(f'/content/dataset/photos-unrized/{file_name}.jpg'.format(file_name))\n",
        "    else :\n",
        "        img = Image.open(f\"{path}/{file}\")\n",
        "        file_name, file_ext = os.path.splitext(file)\n",
        "        if img.mode != 'RGB':\n",
        "            img = img.convert('RGB')\n",
        "        img.save(f'/content/dataset/photos-unrized/{file_name}.jpg'.format(file_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8IHKJg9qbFL",
        "outputId": "d9955b5c-8dc7-4b7a-dcde-47c139ecff26"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = r'/content/dataset/photos-unrized'\n",
        "output_directory_resized = r'/content/dataset/photos'\n",
        "\n",
        "# Pastikan direktori output ada, jika tidak, buat\n",
        "if not os.path.exists(output_directory_resized):\n",
        "    os.makedirs(output_directory_resized)\n",
        "\n",
        "# Tentukan ukuran target (misalnya: 640x480)\n",
        "target_size = (640, 480)\n",
        "\n",
        "for file in os.listdir(path):\n",
        "    if file.endswith(\".jpg\"):\n",
        "        img = Image.open(os.path.join(path, file))\n",
        "        file_name, _ = os.path.splitext(file)\n",
        "\n",
        "        # Ubah ukuran gambar\n",
        "        resized_img = img.resize(target_size)\n",
        "\n",
        "        # Simpan gambar yang sudah diubah ukurannya\n",
        "        resized_img.save(os.path.join(output_directory_resized, f\"{file_name}.jpg\"))"
      ],
      "metadata": {
        "id": "Z7qnRxGwoeuX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk membagi dataset menjadi train dan validation secara acak\n",
        "def split_dataset(annotation_file, train_ratio=0.8):\n",
        "    with open(annotation_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Memecah data menjadi train dan val\n",
        "    train_data, val_data = train_test_split(data[\"annotations\"], train_size=train_ratio, random_state=42)\n",
        "\n",
        "    # Membuat file annotation untuk train dan val\n",
        "    train_data_json = {\"info\": data[\"info\"], \"licenses\": data[\"licenses\"], \"images\": data[\"images\"], \"annotations\": train_data, \"categories\": data[\"categories\"]}\n",
        "    val_data_json = {\"info\": data[\"info\"], \"licenses\": data[\"licenses\"], \"images\": data[\"images\"], \"annotations\": val_data, \"categories\": data[\"categories\"]}\n",
        "\n",
        "    train_annotation_file = os.path.splitext(annotation_file)[0] + \"_train.json\"\n",
        "    val_annotation_file = os.path.splitext(annotation_file)[0] + \"_val.json\"\n",
        "\n",
        "    with open(train_annotation_file, 'w') as train_file:\n",
        "        json.dump(train_data_json, train_file, indent=2)\n",
        "\n",
        "    with open(val_annotation_file, 'w') as val_file:\n",
        "        json.dump(val_data_json, val_file, indent=2)\n",
        "\n",
        "    return train_annotation_file, val_annotation_file\n",
        "\n",
        "# Direktori root yang berisi file annotation\n",
        "root_directory = \"/content/dataset\"\n",
        "\n",
        "# Iterasi melalui setiap file annotation di direktori root\n",
        "for annotation_file in os.listdir(root_directory):\n",
        "    if annotation_file.endswith(\".json\"):\n",
        "        annotation_file_path = os.path.join(root_directory, annotation_file)\n",
        "\n",
        "        # Membagi dataset menjadi train dan validation secara acak\n",
        "        train_annotation_file, val_annotation_file = split_dataset(annotation_file_path)\n",
        "\n",
        "        # Registrasi dataset COCO untuk train dan validation\n",
        "        register_coco_instances(f\"custom_dataset_train_{annotation_file}\", {}, train_annotation_file, os.path.join(root_directory, \"photos\"))\n",
        "        register_coco_instances(f\"custom_dataset_val_{annotation_file}\", {}, val_annotation_file, os.path.join(root_directory, \"photos\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "yw91cRKtq5EV",
        "outputId": "5114021e-692d-4e3c-915c-7420c1532586"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-bcb8abad6910>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Registrasi dataset COCO untuk train dan validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mregister_coco_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"custom_dataset_train_{annotation_file}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_annotation_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"photos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mregister_coco_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"custom_dataset_val_{annotation_file}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_annotation_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"photos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/detectron2/data/datasets/coco.py\u001b[0m in \u001b[0;36mregister_coco_instances\u001b[0;34m(name, metadata, json_file, image_root)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;31m# 1. register a function which returns dicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m     \u001b[0mDatasetCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_coco_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;31m# 2. Optionally, add metadata about this dataset,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/detectron2/data/catalog.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, name, func)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \"\"\"\n\u001b[1;32m     36\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"You must register a function with `DatasetCatalog.register`!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dataset '{}' is already registered!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Dataset 'custom_dataset_train_all_annotations_coco.json' is already registered!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterasi melalui setiap file annotation di direktori root untuk melatih model\n",
        "for annotation_file in os.listdir(root_directory):\n",
        "    if annotation_file.endswith(\"_train.json\"):\n",
        "        annotation_file_path = os.path.join(root_directory, annotation_file)\n",
        "\n",
        "        # Registrasi dataset COCO untuk train dan validation\n",
        "        dataset_name = f\"custom_dataset_train_{annotation_file}\"  # Sesuaikan dengan nama yang digunakan pada registrasi\n",
        "        # register_coco_instances(dataset_name, {}, annotation_file_path, os.path.join(root_directory, \"photos\"))\n",
        "\n",
        "        # Inisialisasi metadata untuk dataset\n",
        "        metadata = MetadataCatalog.get(dataset_name)  # Menggunakan nama dataset yang sesuai\n",
        "\n",
        "        # Konfigurasi model Detectron2\n",
        "        cfg = get_cfg()\n",
        "        cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "        cfg.DATASETS.TRAIN = (dataset_name,)  # Menggunakan nama dataset yang sesuai\n",
        "        cfg.DATASETS.TEST = ()  # Sesuaikan dengan dataset pengujian jika diperlukan\n",
        "        cfg.DATALOADER.NUM_WORKERS = 2\n",
        "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Menggunakan pre-trained weights\n",
        "        cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "        cfg.SOLVER.BASE_LR = 0.00025\n",
        "        cfg.SOLVER.MAX_ITER = 5000\n",
        "        cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "        cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\n",
        "\n",
        "        # Melatih model\n",
        "        trainer = DefaultTrainer(cfg)\n",
        "        trainer.resume_or_load(resume=False)\n",
        "        trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VB5UKjorIlt",
        "outputId": "335fc746-09f6-4f65-c9c0-fc728b5d0645"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01/02 15:07:34 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "[01/02 15:07:34 d2.data.datasets.coco]: Loaded 370 images in COCO format from /content/dataset/all_annotations_coco_train.json\n",
            "WARNING [01/02 15:07:34 d2.data.datasets.coco]: Filtered out 8 instances without valid segmentation. There might be issues in your dataset generation process.  Please check https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html carefully\n",
            "[01/02 15:07:34 d2.data.build]: Removed 82 images with no usable annotations. 288 images left.\n",
            "[01/02 15:07:34 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[01/02 15:07:34 d2.data.build]: Using training sampler TrainingSampler\n",
            "[01/02 15:07:34 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[01/02 15:07:34 d2.data.common]: Serializing 288 elements to byte tensors and concatenating them all ...\n",
            "[01/02 15:07:34 d2.data.common]: Serialized dataset takes 0.09 MiB\n",
            "[01/02 15:07:34 d2.data.build]: Making batched data loader with batch_size=2\n",
            "WARNING [01/02 15:07:34 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[01/02 15:07:34 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01/02 15:07:35 d2.engine.train_loop]: Starting training from iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01/02 15:07:47 d2.utils.events]:  eta: 0:30:32  iter: 19  total_loss: 1.776  loss_cls: 1.441  loss_box_reg: 0.3051  loss_rpn_cls: 0.0208  loss_rpn_loc: 0.01338    time: 0.3762  last_time: 0.3428  data_time: 0.0245  last_data_time: 0.0052   lr: 4.9953e-06  max_mem: 3022M\n",
            "[01/02 15:08:27 d2.utils.events]:  eta: 0:30:51  iter: 39  total_loss: 1.66  loss_cls: 1.329  loss_box_reg: 0.2711  loss_rpn_cls: 0.0237  loss_rpn_loc: 0.01693    time: 0.3816  last_time: 0.3641  data_time: 0.0111  last_data_time: 0.0058   lr: 9.9902e-06  max_mem: 3022M\n",
            "[01/02 15:08:35 d2.utils.events]:  eta: 0:30:33  iter: 59  total_loss: 1.504  loss_cls: 1.092  loss_box_reg: 0.2665  loss_rpn_cls: 0.02043  loss_rpn_loc: 0.0115    time: 0.3766  last_time: 0.3615  data_time: 0.0091  last_data_time: 0.0115   lr: 1.4985e-05  max_mem: 3022M\n",
            "[01/02 15:08:42 d2.utils.events]:  eta: 0:30:30  iter: 79  total_loss: 1.218  loss_cls: 0.8904  loss_box_reg: 0.2646  loss_rpn_cls: 0.02324  loss_rpn_loc: 0.01421    time: 0.3777  last_time: 0.3446  data_time: 0.0114  last_data_time: 0.0064   lr: 1.998e-05  max_mem: 3022M\n",
            "[01/02 15:08:50 d2.utils.events]:  eta: 0:30:35  iter: 99  total_loss: 1.056  loss_cls: 0.6844  loss_box_reg: 0.3269  loss_rpn_cls: 0.0114  loss_rpn_loc: 0.01875    time: 0.3788  last_time: 0.3715  data_time: 0.0087  last_data_time: 0.0233   lr: 2.4975e-05  max_mem: 3022M\n",
            "[01/02 15:08:58 d2.utils.events]:  eta: 0:30:40  iter: 119  total_loss: 0.8502  loss_cls: 0.5079  loss_box_reg: 0.2487  loss_rpn_cls: 0.02964  loss_rpn_loc: 0.01772    time: 0.3828  last_time: 0.3472  data_time: 0.0108  last_data_time: 0.0060   lr: 2.997e-05  max_mem: 3022M\n",
            "[01/02 15:09:06 d2.utils.events]:  eta: 0:30:46  iter: 139  total_loss: 0.7432  loss_cls: 0.405  loss_box_reg: 0.2598  loss_rpn_cls: 0.01288  loss_rpn_loc: 0.01299    time: 0.3851  last_time: 0.4583  data_time: 0.0119  last_data_time: 0.0146   lr: 3.4965e-05  max_mem: 3022M\n",
            "[01/02 15:09:13 d2.utils.events]:  eta: 0:30:41  iter: 159  total_loss: 0.6674  loss_cls: 0.3435  loss_box_reg: 0.2577  loss_rpn_cls: 0.02742  loss_rpn_loc: 0.01671    time: 0.3840  last_time: 0.3824  data_time: 0.0091  last_data_time: 0.0186   lr: 3.996e-05  max_mem: 3022M\n",
            "[01/02 15:09:21 d2.utils.events]:  eta: 0:30:35  iter: 179  total_loss: 0.6758  loss_cls: 0.3391  loss_box_reg: 0.2835  loss_rpn_cls: 0.0268  loss_rpn_loc: 0.01612    time: 0.3836  last_time: 0.3832  data_time: 0.0134  last_data_time: 0.0063   lr: 4.4955e-05  max_mem: 3022M\n",
            "[01/02 15:09:29 d2.utils.events]:  eta: 0:30:30  iter: 199  total_loss: 0.6764  loss_cls: 0.2943  loss_box_reg: 0.3059  loss_rpn_cls: 0.02164  loss_rpn_loc: 0.02416    time: 0.3845  last_time: 0.4487  data_time: 0.0087  last_data_time: 0.0046   lr: 4.995e-05  max_mem: 3022M\n",
            "[01/02 15:09:37 d2.utils.events]:  eta: 0:30:25  iter: 219  total_loss: 0.6645  loss_cls: 0.3004  loss_box_reg: 0.2912  loss_rpn_cls: 0.01123  loss_rpn_loc: 0.01833    time: 0.3848  last_time: 0.3658  data_time: 0.0127  last_data_time: 0.0057   lr: 5.4945e-05  max_mem: 3022M\n",
            "[01/02 15:09:44 d2.utils.events]:  eta: 0:30:15  iter: 239  total_loss: 0.6916  loss_cls: 0.2834  loss_box_reg: 0.3309  loss_rpn_cls: 0.008015  loss_rpn_loc: 0.01319    time: 0.3845  last_time: 0.3953  data_time: 0.0127  last_data_time: 0.0274   lr: 5.994e-05  max_mem: 3022M\n",
            "[01/02 15:09:52 d2.utils.events]:  eta: 0:30:03  iter: 259  total_loss: 0.7372  loss_cls: 0.3259  loss_box_reg: 0.3927  loss_rpn_cls: 0.005462  loss_rpn_loc: 0.0111    time: 0.3829  last_time: 0.3861  data_time: 0.0088  last_data_time: 0.0119   lr: 6.4935e-05  max_mem: 3022M\n",
            "[01/02 15:10:00 d2.utils.events]:  eta: 0:29:59  iter: 279  total_loss: 0.5688  loss_cls: 0.2363  loss_box_reg: 0.2778  loss_rpn_cls: 0.0261  loss_rpn_loc: 0.01759    time: 0.3843  last_time: 0.3431  data_time: 0.0130  last_data_time: 0.0054   lr: 6.993e-05  max_mem: 3022M\n",
            "[01/02 15:10:07 d2.utils.events]:  eta: 0:29:51  iter: 299  total_loss: 0.6388  loss_cls: 0.255  loss_box_reg: 0.3212  loss_rpn_cls: 0.01366  loss_rpn_loc: 0.01476    time: 0.3843  last_time: 0.3460  data_time: 0.0080  last_data_time: 0.0058   lr: 7.4925e-05  max_mem: 3022M\n",
            "[01/02 15:10:15 d2.utils.events]:  eta: 0:29:48  iter: 319  total_loss: 0.5935  loss_cls: 0.2251  loss_box_reg: 0.3199  loss_rpn_cls: 0.003664  loss_rpn_loc: 0.01443    time: 0.3854  last_time: 0.4403  data_time: 0.0109  last_data_time: 0.0053   lr: 7.992e-05  max_mem: 3022M\n",
            "[01/02 15:10:24 d2.utils.events]:  eta: 0:29:42  iter: 339  total_loss: 0.5396  loss_cls: 0.2285  loss_box_reg: 0.2734  loss_rpn_cls: 0.01204  loss_rpn_loc: 0.01368    time: 0.3872  last_time: 0.4560  data_time: 0.0121  last_data_time: 0.0174   lr: 8.4915e-05  max_mem: 3022M\n",
            "[01/02 15:10:32 d2.utils.events]:  eta: 0:29:36  iter: 359  total_loss: 0.6512  loss_cls: 0.2632  loss_box_reg: 0.3415  loss_rpn_cls: 0.01487  loss_rpn_loc: 0.01413    time: 0.3882  last_time: 0.4448  data_time: 0.0097  last_data_time: 0.0053   lr: 8.991e-05  max_mem: 3022M\n",
            "[01/02 15:10:40 d2.utils.events]:  eta: 0:29:36  iter: 379  total_loss: 0.5909  loss_cls: 0.2386  loss_box_reg: 0.2933  loss_rpn_cls: 0.01228  loss_rpn_loc: 0.009851    time: 0.3889  last_time: 0.4487  data_time: 0.0142  last_data_time: 0.0058   lr: 9.4905e-05  max_mem: 3022M\n",
            "[01/02 15:10:48 d2.utils.events]:  eta: 0:29:30  iter: 399  total_loss: 0.5406  loss_cls: 0.2214  loss_box_reg: 0.2944  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.01612    time: 0.3899  last_time: 0.3943  data_time: 0.0097  last_data_time: 0.0160   lr: 9.99e-05  max_mem: 3022M\n",
            "[01/02 15:10:56 d2.utils.events]:  eta: 0:29:20  iter: 419  total_loss: 0.5994  loss_cls: 0.2306  loss_box_reg: 0.3421  loss_rpn_cls: 0.008236  loss_rpn_loc: 0.01148    time: 0.3891  last_time: 0.3845  data_time: 0.0110  last_data_time: 0.0053   lr: 0.0001049  max_mem: 3022M\n",
            "[01/02 15:11:03 d2.utils.events]:  eta: 0:29:13  iter: 439  total_loss: 0.5921  loss_cls: 0.2477  loss_box_reg: 0.2993  loss_rpn_cls: 0.01053  loss_rpn_loc: 0.01365    time: 0.3889  last_time: 0.4661  data_time: 0.0123  last_data_time: 0.0253   lr: 0.00010989  max_mem: 3022M\n",
            "[01/02 15:11:11 d2.utils.events]:  eta: 0:29:06  iter: 459  total_loss: 0.584  loss_cls: 0.2103  loss_box_reg: 0.3182  loss_rpn_cls: 0.00897  loss_rpn_loc: 0.01534    time: 0.3891  last_time: 0.4386  data_time: 0.0084  last_data_time: 0.0050   lr: 0.00011489  max_mem: 3022M\n",
            "[01/02 15:11:19 d2.utils.events]:  eta: 0:29:00  iter: 479  total_loss: 0.6149  loss_cls: 0.2368  loss_box_reg: 0.3483  loss_rpn_cls: 0.006572  loss_rpn_loc: 0.01823    time: 0.3895  last_time: 0.4408  data_time: 0.0136  last_data_time: 0.0058   lr: 0.00011988  max_mem: 3022M\n",
            "[01/02 15:11:27 d2.utils.events]:  eta: 0:28:50  iter: 499  total_loss: 0.6353  loss_cls: 0.2551  loss_box_reg: 0.3597  loss_rpn_cls: 0.01004  loss_rpn_loc: 0.01661    time: 0.3890  last_time: 0.3805  data_time: 0.0075  last_data_time: 0.0053   lr: 0.00012488  max_mem: 3022M\n",
            "[01/02 15:11:35 d2.utils.events]:  eta: 0:28:44  iter: 519  total_loss: 0.6496  loss_cls: 0.2461  loss_box_reg: 0.3627  loss_rpn_cls: 0.004622  loss_rpn_loc: 0.01451    time: 0.3898  last_time: 0.3890  data_time: 0.0108  last_data_time: 0.0114   lr: 0.00012987  max_mem: 3022M\n",
            "[01/02 15:11:43 d2.utils.events]:  eta: 0:28:37  iter: 539  total_loss: 0.5849  loss_cls: 0.2232  loss_box_reg: 0.3344  loss_rpn_cls: 0.01072  loss_rpn_loc: 0.01422    time: 0.3903  last_time: 0.4502  data_time: 0.0119  last_data_time: 0.0156   lr: 0.00013487  max_mem: 3022M\n",
            "[01/02 15:11:51 d2.utils.events]:  eta: 0:28:29  iter: 559  total_loss: 0.54  loss_cls: 0.2088  loss_box_reg: 0.3105  loss_rpn_cls: 0.01178  loss_rpn_loc: 0.01547    time: 0.3900  last_time: 0.3825  data_time: 0.0140  last_data_time: 0.0132   lr: 0.00013986  max_mem: 3022M\n",
            "[01/02 15:11:58 d2.utils.events]:  eta: 0:28:20  iter: 579  total_loss: 0.5243  loss_cls: 0.176  loss_box_reg: 0.3121  loss_rpn_cls: 0.005604  loss_rpn_loc: 0.01275    time: 0.3899  last_time: 0.3430  data_time: 0.0136  last_data_time: 0.0059   lr: 0.00014486  max_mem: 3022M\n",
            "[01/02 15:12:06 d2.utils.events]:  eta: 0:28:12  iter: 599  total_loss: 0.5812  loss_cls: 0.2076  loss_box_reg: 0.3251  loss_rpn_cls: 0.008456  loss_rpn_loc: 0.0163    time: 0.3894  last_time: 0.3210  data_time: 0.0076  last_data_time: 0.0127   lr: 0.00014985  max_mem: 3022M\n",
            "[01/02 15:12:14 d2.utils.events]:  eta: 0:28:04  iter: 619  total_loss: 0.5463  loss_cls: 0.1798  loss_box_reg: 0.3294  loss_rpn_cls: 0.008613  loss_rpn_loc: 0.01694    time: 0.3891  last_time: 0.3749  data_time: 0.0119  last_data_time: 0.0125   lr: 0.00015485  max_mem: 3022M\n",
            "[01/02 15:12:21 d2.utils.events]:  eta: 0:27:56  iter: 639  total_loss: 0.6151  loss_cls: 0.2301  loss_box_reg: 0.364  loss_rpn_cls: 0.01173  loss_rpn_loc: 0.01101    time: 0.3890  last_time: 0.4585  data_time: 0.0085  last_data_time: 0.0138   lr: 0.00015984  max_mem: 3022M\n",
            "[01/02 15:12:29 d2.utils.events]:  eta: 0:27:49  iter: 659  total_loss: 0.5529  loss_cls: 0.2019  loss_box_reg: 0.2871  loss_rpn_cls: 0.01051  loss_rpn_loc: 0.01616    time: 0.3892  last_time: 0.4506  data_time: 0.0082  last_data_time: 0.0125   lr: 0.00016484  max_mem: 3022M\n",
            "[01/02 15:12:37 d2.utils.events]:  eta: 0:27:42  iter: 679  total_loss: 0.5164  loss_cls: 0.1788  loss_box_reg: 0.3076  loss_rpn_cls: 0.005406  loss_rpn_loc: 0.01922    time: 0.3895  last_time: 0.4462  data_time: 0.0127  last_data_time: 0.0125   lr: 0.00016983  max_mem: 3022M\n",
            "[01/02 15:12:45 d2.utils.events]:  eta: 0:27:35  iter: 699  total_loss: 0.5483  loss_cls: 0.1687  loss_box_reg: 0.3352  loss_rpn_cls: 0.01085  loss_rpn_loc: 0.01225    time: 0.3899  last_time: 0.4427  data_time: 0.0092  last_data_time: 0.0119   lr: 0.00017483  max_mem: 3022M\n",
            "[01/02 15:12:53 d2.utils.events]:  eta: 0:27:28  iter: 719  total_loss: 0.51  loss_cls: 0.1627  loss_box_reg: 0.2816  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.01446    time: 0.3905  last_time: 0.3470  data_time: 0.0123  last_data_time: 0.0055   lr: 0.00017982  max_mem: 3022M\n",
            "[01/02 15:13:01 d2.utils.events]:  eta: 0:27:21  iter: 739  total_loss: 0.5443  loss_cls: 0.155  loss_box_reg: 0.3702  loss_rpn_cls: 0.006253  loss_rpn_loc: 0.0155    time: 0.3904  last_time: 0.3962  data_time: 0.0120  last_data_time: 0.0197   lr: 0.00018482  max_mem: 3022M\n",
            "[01/02 15:13:09 d2.utils.events]:  eta: 0:27:13  iter: 759  total_loss: 0.4958  loss_cls: 0.1602  loss_box_reg: 0.3198  loss_rpn_cls: 0.008393  loss_rpn_loc: 0.01484    time: 0.3902  last_time: 0.3760  data_time: 0.0088  last_data_time: 0.0138   lr: 0.00018981  max_mem: 3022M\n",
            "[01/02 15:13:17 d2.utils.events]:  eta: 0:27:06  iter: 779  total_loss: 0.5438  loss_cls: 0.185  loss_box_reg: 0.3381  loss_rpn_cls: 0.007701  loss_rpn_loc: 0.01261    time: 0.3905  last_time: 0.4358  data_time: 0.0125  last_data_time: 0.0058   lr: 0.00019481  max_mem: 3022M\n",
            "[01/02 15:13:25 d2.utils.events]:  eta: 0:26:58  iter: 799  total_loss: 0.4979  loss_cls: 0.1329  loss_box_reg: 0.2883  loss_rpn_cls: 0.003984  loss_rpn_loc: 0.01622    time: 0.3904  last_time: 0.4471  data_time: 0.0069  last_data_time: 0.0055   lr: 0.0001998  max_mem: 3022M\n",
            "[01/02 15:13:32 d2.utils.events]:  eta: 0:26:50  iter: 819  total_loss: 0.5838  loss_cls: 0.1803  loss_box_reg: 0.3719  loss_rpn_cls: 0.01121  loss_rpn_loc: 0.01545    time: 0.3902  last_time: 0.4408  data_time: 0.0085  last_data_time: 0.0054   lr: 0.0002048  max_mem: 3022M\n",
            "[01/02 15:13:40 d2.utils.events]:  eta: 0:26:42  iter: 839  total_loss: 0.5086  loss_cls: 0.1818  loss_box_reg: 0.3026  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.01246    time: 0.3902  last_time: 0.3591  data_time: 0.0098  last_data_time: 0.0135   lr: 0.00020979  max_mem: 3022M\n",
            "[01/02 15:13:48 d2.utils.events]:  eta: 0:26:34  iter: 859  total_loss: 0.4412  loss_cls: 0.1472  loss_box_reg: 0.2733  loss_rpn_cls: 0.004878  loss_rpn_loc: 0.01969    time: 0.3903  last_time: 0.3692  data_time: 0.0083  last_data_time: 0.0057   lr: 0.00021479  max_mem: 3022M\n",
            "[01/02 15:13:56 d2.utils.events]:  eta: 0:26:27  iter: 879  total_loss: 0.4777  loss_cls: 0.1331  loss_box_reg: 0.2852  loss_rpn_cls: 0.007875  loss_rpn_loc: 0.01721    time: 0.3905  last_time: 0.3251  data_time: 0.0142  last_data_time: 0.0059   lr: 0.00021978  max_mem: 3022M\n",
            "[01/02 15:14:03 d2.utils.events]:  eta: 0:26:19  iter: 899  total_loss: 0.485  loss_cls: 0.1652  loss_box_reg: 0.2866  loss_rpn_cls: 0.005944  loss_rpn_loc: 0.01089    time: 0.3901  last_time: 0.3940  data_time: 0.0074  last_data_time: 0.0137   lr: 0.00022478  max_mem: 3022M\n",
            "[01/02 15:14:12 d2.utils.events]:  eta: 0:26:11  iter: 919  total_loss: 0.4781  loss_cls: 0.1459  loss_box_reg: 0.2717  loss_rpn_cls: 0.007365  loss_rpn_loc: 0.01439    time: 0.3904  last_time: 0.3843  data_time: 0.0129  last_data_time: 0.0058   lr: 0.00022977  max_mem: 3022M\n",
            "[01/02 15:14:19 d2.utils.events]:  eta: 0:26:04  iter: 939  total_loss: 0.4603  loss_cls: 0.1071  loss_box_reg: 0.2596  loss_rpn_cls: 0.003445  loss_rpn_loc: 0.01335    time: 0.3904  last_time: 0.4101  data_time: 0.0108  last_data_time: 0.0251   lr: 0.00023477  max_mem: 3022M\n",
            "[01/02 15:14:27 d2.utils.events]:  eta: 0:25:57  iter: 959  total_loss: 0.4699  loss_cls: 0.1307  loss_box_reg: 0.2992  loss_rpn_cls: 0.003716  loss_rpn_loc: 0.0224    time: 0.3906  last_time: 0.4449  data_time: 0.0097  last_data_time: 0.0150   lr: 0.00023976  max_mem: 3022M\n",
            "[01/02 15:14:35 d2.utils.events]:  eta: 0:25:49  iter: 979  total_loss: 0.557  loss_cls: 0.1625  loss_box_reg: 0.3  loss_rpn_cls: 0.009176  loss_rpn_loc: 0.01802    time: 0.3908  last_time: 0.3946  data_time: 0.0128  last_data_time: 0.0147   lr: 0.00024476  max_mem: 3022M\n",
            "[01/02 15:14:43 d2.utils.events]:  eta: 0:25:41  iter: 999  total_loss: 0.4556  loss_cls: 0.108  loss_box_reg: 0.2823  loss_rpn_cls: 0.006122  loss_rpn_loc: 0.01903    time: 0.3908  last_time: 0.3492  data_time: 0.0090  last_data_time: 0.0056   lr: 0.00024975  max_mem: 3022M\n",
            "[01/02 15:14:51 d2.utils.events]:  eta: 0:25:34  iter: 1019  total_loss: 0.4474  loss_cls: 0.1072  loss_box_reg: 0.2988  loss_rpn_cls: 0.006096  loss_rpn_loc: 0.009851    time: 0.3909  last_time: 0.3520  data_time: 0.0114  last_data_time: 0.0122   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:14:59 d2.utils.events]:  eta: 0:25:28  iter: 1039  total_loss: 0.3964  loss_cls: 0.1036  loss_box_reg: 0.2754  loss_rpn_cls: 0.005959  loss_rpn_loc: 0.01218    time: 0.3911  last_time: 0.4087  data_time: 0.0100  last_data_time: 0.0210   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:15:07 d2.utils.events]:  eta: 0:25:20  iter: 1059  total_loss: 0.6215  loss_cls: 0.1886  loss_box_reg: 0.4077  loss_rpn_cls: 0.006171  loss_rpn_loc: 0.01175    time: 0.3908  last_time: 0.3689  data_time: 0.0098  last_data_time: 0.0053   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:15:15 d2.utils.events]:  eta: 0:25:13  iter: 1079  total_loss: 0.432  loss_cls: 0.1235  loss_box_reg: 0.2762  loss_rpn_cls: 0.006676  loss_rpn_loc: 0.02088    time: 0.3908  last_time: 0.3163  data_time: 0.0121  last_data_time: 0.0057   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:15:22 d2.utils.events]:  eta: 0:25:06  iter: 1099  total_loss: 0.3277  loss_cls: 0.08615  loss_box_reg: 0.2268  loss_rpn_cls: 0.006438  loss_rpn_loc: 0.01105    time: 0.3905  last_time: 0.3799  data_time: 0.0098  last_data_time: 0.0131   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:15:30 d2.utils.events]:  eta: 0:24:58  iter: 1119  total_loss: 0.4122  loss_cls: 0.1267  loss_box_reg: 0.2577  loss_rpn_cls: 0.004203  loss_rpn_loc: 0.02354    time: 0.3907  last_time: 0.4441  data_time: 0.0112  last_data_time: 0.0144   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:15:38 d2.utils.events]:  eta: 0:24:49  iter: 1139  total_loss: 0.5065  loss_cls: 0.1486  loss_box_reg: 0.2764  loss_rpn_cls: 0.00593  loss_rpn_loc: 0.01338    time: 0.3907  last_time: 0.4545  data_time: 0.0097  last_data_time: 0.0135   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:15:45 d2.utils.events]:  eta: 0:24:41  iter: 1159  total_loss: 0.5152  loss_cls: 0.1257  loss_box_reg: 0.3042  loss_rpn_cls: 0.004966  loss_rpn_loc: 0.009072    time: 0.3904  last_time: 0.3912  data_time: 0.0069  last_data_time: 0.0057   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:15:53 d2.utils.events]:  eta: 0:24:34  iter: 1179  total_loss: 0.4179  loss_cls: 0.1177  loss_box_reg: 0.2719  loss_rpn_cls: 0.005845  loss_rpn_loc: 0.01376    time: 0.3905  last_time: 0.4412  data_time: 0.0146  last_data_time: 0.0054   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:16:01 d2.utils.events]:  eta: 0:24:26  iter: 1199  total_loss: 0.44  loss_cls: 0.1275  loss_box_reg: 0.2609  loss_rpn_cls: 0.005994  loss_rpn_loc: 0.01468    time: 0.3903  last_time: 0.3845  data_time: 0.0085  last_data_time: 0.0055   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:16:09 d2.utils.events]:  eta: 0:24:19  iter: 1219  total_loss: 0.5486  loss_cls: 0.175  loss_box_reg: 0.3435  loss_rpn_cls: 0.007871  loss_rpn_loc: 0.009388    time: 0.3904  last_time: 0.3758  data_time: 0.0125  last_data_time: 0.0125   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:16:16 d2.utils.events]:  eta: 0:24:11  iter: 1239  total_loss: 0.3983  loss_cls: 0.1008  loss_box_reg: 0.2669  loss_rpn_cls: 0.007197  loss_rpn_loc: 0.01646    time: 0.3900  last_time: 0.3659  data_time: 0.0085  last_data_time: 0.0055   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:16:24 d2.utils.events]:  eta: 0:24:04  iter: 1259  total_loss: 0.4168  loss_cls: 0.1164  loss_box_reg: 0.2897  loss_rpn_cls: 0.005273  loss_rpn_loc: 0.01032    time: 0.3898  last_time: 0.3700  data_time: 0.0097  last_data_time: 0.0059   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:16:32 d2.utils.events]:  eta: 0:23:56  iter: 1279  total_loss: 0.3559  loss_cls: 0.09512  loss_box_reg: 0.2288  loss_rpn_cls: 0.006922  loss_rpn_loc: 0.01486    time: 0.3898  last_time: 0.3915  data_time: 0.0110  last_data_time: 0.0057   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:16:40 d2.utils.events]:  eta: 0:23:49  iter: 1299  total_loss: 0.5099  loss_cls: 0.134  loss_box_reg: 0.3245  loss_rpn_cls: 0.005013  loss_rpn_loc: 0.01381    time: 0.3901  last_time: 0.3877  data_time: 0.0099  last_data_time: 0.0068   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:16:48 d2.utils.events]:  eta: 0:23:41  iter: 1319  total_loss: 0.4214  loss_cls: 0.1018  loss_box_reg: 0.2795  loss_rpn_cls: 0.003433  loss_rpn_loc: 0.02074    time: 0.3901  last_time: 0.4499  data_time: 0.0094  last_data_time: 0.0129   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:16:55 d2.utils.events]:  eta: 0:23:33  iter: 1339  total_loss: 0.4465  loss_cls: 0.1081  loss_box_reg: 0.3241  loss_rpn_cls: 0.004532  loss_rpn_loc: 0.02016    time: 0.3901  last_time: 0.3961  data_time: 0.0083  last_data_time: 0.0135   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:17:04 d2.utils.events]:  eta: 0:23:25  iter: 1359  total_loss: 0.4274  loss_cls: 0.1051  loss_box_reg: 0.2856  loss_rpn_cls: 0.003468  loss_rpn_loc: 0.01046    time: 0.3904  last_time: 0.4421  data_time: 0.0107  last_data_time: 0.0057   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:17:11 d2.utils.events]:  eta: 0:23:17  iter: 1379  total_loss: 0.399  loss_cls: 0.09364  loss_box_reg: 0.2682  loss_rpn_cls: 0.003784  loss_rpn_loc: 0.01266    time: 0.3903  last_time: 0.4627  data_time: 0.0086  last_data_time: 0.0220   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:17:19 d2.utils.events]:  eta: 0:23:09  iter: 1399  total_loss: 0.3986  loss_cls: 0.119  loss_box_reg: 0.2498  loss_rpn_cls: 0.002996  loss_rpn_loc: 0.01594    time: 0.3905  last_time: 0.3219  data_time: 0.0074  last_data_time: 0.0188   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:17:27 d2.utils.events]:  eta: 0:23:02  iter: 1419  total_loss: 0.4091  loss_cls: 0.09661  loss_box_reg: 0.2889  loss_rpn_cls: 0.003489  loss_rpn_loc: 0.01231    time: 0.3903  last_time: 0.3552  data_time: 0.0141  last_data_time: 0.0135   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:17:35 d2.utils.events]:  eta: 0:22:54  iter: 1439  total_loss: 0.3947  loss_cls: 0.1  loss_box_reg: 0.2581  loss_rpn_cls: 0.005449  loss_rpn_loc: 0.0108    time: 0.3904  last_time: 0.3200  data_time: 0.0093  last_data_time: 0.0258   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:17:43 d2.utils.events]:  eta: 0:22:46  iter: 1459  total_loss: 0.5416  loss_cls: 0.1618  loss_box_reg: 0.3171  loss_rpn_cls: 0.005505  loss_rpn_loc: 0.00859    time: 0.3903  last_time: 0.3746  data_time: 0.0134  last_data_time: 0.0118   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:17:51 d2.utils.events]:  eta: 0:22:38  iter: 1479  total_loss: 0.4123  loss_cls: 0.101  loss_box_reg: 0.2728  loss_rpn_cls: 0.008474  loss_rpn_loc: 0.01071    time: 0.3906  last_time: 0.4445  data_time: 0.0120  last_data_time: 0.0052   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:17:59 d2.utils.events]:  eta: 0:22:32  iter: 1499  total_loss: 0.4469  loss_cls: 0.1355  loss_box_reg: 0.3103  loss_rpn_cls: 0.001856  loss_rpn_loc: 0.01899    time: 0.3908  last_time: 0.2923  data_time: 0.0096  last_data_time: 0.0054   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:18:07 d2.utils.events]:  eta: 0:22:24  iter: 1519  total_loss: 0.4086  loss_cls: 0.08193  loss_box_reg: 0.2848  loss_rpn_cls: 0.003115  loss_rpn_loc: 0.01938    time: 0.3909  last_time: 0.3932  data_time: 0.0121  last_data_time: 0.0139   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:18:15 d2.utils.events]:  eta: 0:22:16  iter: 1539  total_loss: 0.4612  loss_cls: 0.1041  loss_box_reg: 0.3009  loss_rpn_cls: 0.005884  loss_rpn_loc: 0.01074    time: 0.3908  last_time: 0.3930  data_time: 0.0073  last_data_time: 0.0054   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:18:23 d2.utils.events]:  eta: 0:22:10  iter: 1559  total_loss: 0.3447  loss_cls: 0.1017  loss_box_reg: 0.2278  loss_rpn_cls: 0.003944  loss_rpn_loc: 0.01573    time: 0.3910  last_time: 0.4440  data_time: 0.0138  last_data_time: 0.0118   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:18:30 d2.utils.events]:  eta: 0:22:03  iter: 1579  total_loss: 0.3441  loss_cls: 0.07908  loss_box_reg: 0.2303  loss_rpn_cls: 0.005624  loss_rpn_loc: 0.0125    time: 0.3909  last_time: 0.4402  data_time: 0.0105  last_data_time: 0.0108   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:18:38 d2.utils.events]:  eta: 0:21:55  iter: 1599  total_loss: 0.4319  loss_cls: 0.1063  loss_box_reg: 0.2729  loss_rpn_cls: 0.005389  loss_rpn_loc: 0.02064    time: 0.3908  last_time: 0.3821  data_time: 0.0074  last_data_time: 0.0131   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:18:46 d2.utils.events]:  eta: 0:21:49  iter: 1619  total_loss: 0.488  loss_cls: 0.1177  loss_box_reg: 0.2982  loss_rpn_cls: 0.005942  loss_rpn_loc: 0.01159    time: 0.3910  last_time: 0.3846  data_time: 0.0122  last_data_time: 0.0049   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:18:54 d2.utils.events]:  eta: 0:21:41  iter: 1639  total_loss: 0.3349  loss_cls: 0.08334  loss_box_reg: 0.2382  loss_rpn_cls: 0.004444  loss_rpn_loc: 0.01905    time: 0.3911  last_time: 0.3188  data_time: 0.0135  last_data_time: 0.0189   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:19:02 d2.utils.events]:  eta: 0:21:32  iter: 1659  total_loss: 0.2801  loss_cls: 0.06302  loss_box_reg: 0.1835  loss_rpn_cls: 0.002642  loss_rpn_loc: 0.01044    time: 0.3910  last_time: 0.3708  data_time: 0.0091  last_data_time: 0.0122   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:19:10 d2.utils.events]:  eta: 0:21:25  iter: 1679  total_loss: 0.483  loss_cls: 0.1269  loss_box_reg: 0.326  loss_rpn_cls: 0.002879  loss_rpn_loc: 0.01062    time: 0.3910  last_time: 0.3875  data_time: 0.0145  last_data_time: 0.0122   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:19:18 d2.utils.events]:  eta: 0:21:17  iter: 1699  total_loss: 0.3823  loss_cls: 0.09675  loss_box_reg: 0.2646  loss_rpn_cls: 0.003382  loss_rpn_loc: 0.01193    time: 0.3911  last_time: 0.4431  data_time: 0.0098  last_data_time: 0.0052   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:19:26 d2.utils.events]:  eta: 0:21:09  iter: 1719  total_loss: 0.3647  loss_cls: 0.08811  loss_box_reg: 0.2353  loss_rpn_cls: 0.002261  loss_rpn_loc: 0.01544    time: 0.3913  last_time: 0.3864  data_time: 0.0122  last_data_time: 0.0050   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:19:34 d2.utils.events]:  eta: 0:21:01  iter: 1739  total_loss: 0.3667  loss_cls: 0.09775  loss_box_reg: 0.2529  loss_rpn_cls: 0.00336  loss_rpn_loc: 0.01452    time: 0.3913  last_time: 0.4632  data_time: 0.0107  last_data_time: 0.0251   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:19:42 d2.utils.events]:  eta: 0:20:55  iter: 1759  total_loss: 0.2671  loss_cls: 0.07054  loss_box_reg: 0.1714  loss_rpn_cls: 0.002947  loss_rpn_loc: 0.01915    time: 0.3916  last_time: 0.3475  data_time: 0.0091  last_data_time: 0.0058   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:19:50 d2.utils.events]:  eta: 0:20:47  iter: 1779  total_loss: 0.3753  loss_cls: 0.09556  loss_box_reg: 0.2257  loss_rpn_cls: 0.005684  loss_rpn_loc: 0.01447    time: 0.3916  last_time: 0.3489  data_time: 0.0113  last_data_time: 0.0057   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:19:58 d2.utils.events]:  eta: 0:20:40  iter: 1799  total_loss: 0.4224  loss_cls: 0.1102  loss_box_reg: 0.26  loss_rpn_cls: 0.004053  loss_rpn_loc: 0.01358    time: 0.3917  last_time: 0.3549  data_time: 0.0088  last_data_time: 0.0191   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:20:06 d2.utils.events]:  eta: 0:20:32  iter: 1819  total_loss: 0.3853  loss_cls: 0.08411  loss_box_reg: 0.2644  loss_rpn_cls: 0.00374  loss_rpn_loc: 0.009968    time: 0.3918  last_time: 0.3945  data_time: 0.0121  last_data_time: 0.0049   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:20:14 d2.utils.events]:  eta: 0:20:25  iter: 1839  total_loss: 0.3945  loss_cls: 0.09787  loss_box_reg: 0.2595  loss_rpn_cls: 0.004039  loss_rpn_loc: 0.01063    time: 0.3919  last_time: 0.4588  data_time: 0.0131  last_data_time: 0.0242   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:20:22 d2.utils.events]:  eta: 0:20:17  iter: 1859  total_loss: 0.373  loss_cls: 0.1002  loss_box_reg: 0.2396  loss_rpn_cls: 0.004212  loss_rpn_loc: 0.0141    time: 0.3918  last_time: 0.3013  data_time: 0.0079  last_data_time: 0.0125   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:20:30 d2.utils.events]:  eta: 0:20:09  iter: 1879  total_loss: 0.3568  loss_cls: 0.08121  loss_box_reg: 0.2242  loss_rpn_cls: 0.003119  loss_rpn_loc: 0.02047    time: 0.3919  last_time: 0.3888  data_time: 0.0099  last_data_time: 0.0074   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:20:37 d2.utils.events]:  eta: 0:20:01  iter: 1899  total_loss: 0.3999  loss_cls: 0.09807  loss_box_reg: 0.2626  loss_rpn_cls: 0.00388  loss_rpn_loc: 0.01496    time: 0.3917  last_time: 0.4386  data_time: 0.0085  last_data_time: 0.0054   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:20:45 d2.utils.events]:  eta: 0:19:54  iter: 1919  total_loss: 0.3767  loss_cls: 0.07672  loss_box_reg: 0.2538  loss_rpn_cls: 0.003939  loss_rpn_loc: 0.01648    time: 0.3917  last_time: 0.3523  data_time: 0.0084  last_data_time: 0.0053   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:20:53 d2.utils.events]:  eta: 0:19:46  iter: 1939  total_loss: 0.3671  loss_cls: 0.08767  loss_box_reg: 0.2481  loss_rpn_cls: 0.001987  loss_rpn_loc: 0.009712    time: 0.3916  last_time: 0.4035  data_time: 0.0099  last_data_time: 0.0187   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:21:01 d2.utils.events]:  eta: 0:19:39  iter: 1959  total_loss: 0.4339  loss_cls: 0.1015  loss_box_reg: 0.3025  loss_rpn_cls: 0.005816  loss_rpn_loc: 0.01317    time: 0.3917  last_time: 0.3143  data_time: 0.0083  last_data_time: 0.0054   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:21:09 d2.utils.events]:  eta: 0:19:31  iter: 1979  total_loss: 0.3744  loss_cls: 0.07943  loss_box_reg: 0.2878  loss_rpn_cls: 0.002845  loss_rpn_loc: 0.01224    time: 0.3917  last_time: 0.4396  data_time: 0.0139  last_data_time: 0.0048   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:21:16 d2.utils.events]:  eta: 0:19:23  iter: 1999  total_loss: 0.383  loss_cls: 0.08929  loss_box_reg: 0.2536  loss_rpn_cls: 0.004636  loss_rpn_loc: 0.01223    time: 0.3917  last_time: 0.4387  data_time: 0.0086  last_data_time: 0.0061   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:21:25 d2.utils.events]:  eta: 0:19:16  iter: 2019  total_loss: 0.3482  loss_cls: 0.08833  loss_box_reg: 0.2314  loss_rpn_cls: 0.001323  loss_rpn_loc: 0.01249    time: 0.3918  last_time: 0.3916  data_time: 0.0146  last_data_time: 0.0123   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:21:32 d2.utils.events]:  eta: 0:19:08  iter: 2039  total_loss: 0.3922  loss_cls: 0.08108  loss_box_reg: 0.2863  loss_rpn_cls: 0.003676  loss_rpn_loc: 0.01125    time: 0.3917  last_time: 0.4003  data_time: 0.0114  last_data_time: 0.0168   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:21:40 d2.utils.events]:  eta: 0:19:02  iter: 2059  total_loss: 0.3607  loss_cls: 0.07916  loss_box_reg: 0.2386  loss_rpn_cls: 0.001343  loss_rpn_loc: 0.01129    time: 0.3918  last_time: 0.4450  data_time: 0.0112  last_data_time: 0.0129   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:21:48 d2.utils.events]:  eta: 0:18:54  iter: 2079  total_loss: 0.4018  loss_cls: 0.09981  loss_box_reg: 0.2929  loss_rpn_cls: 0.0011  loss_rpn_loc: 0.00832    time: 0.3917  last_time: 0.3864  data_time: 0.0125  last_data_time: 0.0059   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:21:55 d2.utils.events]:  eta: 0:18:46  iter: 2099  total_loss: 0.367  loss_cls: 0.08228  loss_box_reg: 0.244  loss_rpn_cls: 0.002085  loss_rpn_loc: 0.01527    time: 0.3916  last_time: 0.3849  data_time: 0.0084  last_data_time: 0.0130   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:22:03 d2.utils.events]:  eta: 0:18:38  iter: 2119  total_loss: 0.3257  loss_cls: 0.09312  loss_box_reg: 0.2272  loss_rpn_cls: 0.00146  loss_rpn_loc: 0.01034    time: 0.3915  last_time: 0.4374  data_time: 0.0126  last_data_time: 0.0061   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:22:11 d2.utils.events]:  eta: 0:18:30  iter: 2139  total_loss: 0.3632  loss_cls: 0.09853  loss_box_reg: 0.2603  loss_rpn_cls: 0.002847  loss_rpn_loc: 0.008031    time: 0.3914  last_time: 0.4081  data_time: 0.0115  last_data_time: 0.0203   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:22:18 d2.utils.events]:  eta: 0:18:23  iter: 2159  total_loss: 0.3623  loss_cls: 0.07638  loss_box_reg: 0.2276  loss_rpn_cls: 0.003005  loss_rpn_loc: 0.01134    time: 0.3913  last_time: 0.4445  data_time: 0.0114  last_data_time: 0.0132   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:22:26 d2.utils.events]:  eta: 0:18:15  iter: 2179  total_loss: 0.2709  loss_cls: 0.06543  loss_box_reg: 0.2044  loss_rpn_cls: 0.00167  loss_rpn_loc: 0.01592    time: 0.3914  last_time: 0.4395  data_time: 0.0130  last_data_time: 0.0054   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:22:34 d2.utils.events]:  eta: 0:18:08  iter: 2199  total_loss: 0.3164  loss_cls: 0.07251  loss_box_reg: 0.2088  loss_rpn_cls: 0.002169  loss_rpn_loc: 0.01054    time: 0.3915  last_time: 0.4499  data_time: 0.0107  last_data_time: 0.0124   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:22:42 d2.utils.events]:  eta: 0:18:00  iter: 2219  total_loss: 0.3584  loss_cls: 0.08251  loss_box_reg: 0.2436  loss_rpn_cls: 0.004138  loss_rpn_loc: 0.01612    time: 0.3914  last_time: 0.4451  data_time: 0.0112  last_data_time: 0.0121   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:22:50 d2.utils.events]:  eta: 0:17:53  iter: 2239  total_loss: 0.392  loss_cls: 0.09346  loss_box_reg: 0.2673  loss_rpn_cls: 0.003455  loss_rpn_loc: 0.01374    time: 0.3915  last_time: 0.4562  data_time: 0.0099  last_data_time: 0.0239   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:22:58 d2.utils.events]:  eta: 0:17:47  iter: 2259  total_loss: 0.3223  loss_cls: 0.08469  loss_box_reg: 0.211  loss_rpn_cls: 0.002613  loss_rpn_loc: 0.01605    time: 0.3914  last_time: 0.3162  data_time: 0.0101  last_data_time: 0.0063   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:23:06 d2.utils.events]:  eta: 0:17:40  iter: 2279  total_loss: 0.2679  loss_cls: 0.06364  loss_box_reg: 0.1747  loss_rpn_cls: 0.003565  loss_rpn_loc: 0.01549    time: 0.3916  last_time: 0.4430  data_time: 0.0121  last_data_time: 0.0061   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:23:14 d2.utils.events]:  eta: 0:17:32  iter: 2299  total_loss: 0.3693  loss_cls: 0.08234  loss_box_reg: 0.2491  loss_rpn_cls: 0.001977  loss_rpn_loc: 0.01004    time: 0.3917  last_time: 0.3918  data_time: 0.0095  last_data_time: 0.0125   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:23:22 d2.utils.events]:  eta: 0:17:24  iter: 2319  total_loss: 0.3845  loss_cls: 0.08306  loss_box_reg: 0.2621  loss_rpn_cls: 0.00219  loss_rpn_loc: 0.009784    time: 0.3917  last_time: 0.4430  data_time: 0.0111  last_data_time: 0.0160   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:23:30 d2.utils.events]:  eta: 0:17:17  iter: 2339  total_loss: 0.2962  loss_cls: 0.07234  loss_box_reg: 0.192  loss_rpn_cls: 0.003728  loss_rpn_loc: 0.01229    time: 0.3920  last_time: 0.4635  data_time: 0.0129  last_data_time: 0.0245   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:23:38 d2.utils.events]:  eta: 0:17:08  iter: 2359  total_loss: 0.295  loss_cls: 0.06234  loss_box_reg: 0.2082  loss_rpn_cls: 0.002353  loss_rpn_loc: 0.0102    time: 0.3919  last_time: 0.3249  data_time: 0.0098  last_data_time: 0.0138   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:23:46 d2.utils.events]:  eta: 0:17:01  iter: 2379  total_loss: 0.3126  loss_cls: 0.06857  loss_box_reg: 0.2192  loss_rpn_cls: 0.002062  loss_rpn_loc: 0.01036    time: 0.3921  last_time: 0.4412  data_time: 0.0132  last_data_time: 0.0067   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:23:54 d2.utils.events]:  eta: 0:16:53  iter: 2399  total_loss: 0.4392  loss_cls: 0.09517  loss_box_reg: 0.2791  loss_rpn_cls: 0.001658  loss_rpn_loc: 0.009918    time: 0.3920  last_time: 0.3942  data_time: 0.0094  last_data_time: 0.0252   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:24:02 d2.utils.events]:  eta: 0:16:45  iter: 2419  total_loss: 0.2808  loss_cls: 0.05783  loss_box_reg: 0.2043  loss_rpn_cls: 0.002144  loss_rpn_loc: 0.01592    time: 0.3921  last_time: 0.4475  data_time: 0.0134  last_data_time: 0.0165   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:24:10 d2.utils.events]:  eta: 0:16:38  iter: 2439  total_loss: 0.3354  loss_cls: 0.08765  loss_box_reg: 0.2177  loss_rpn_cls: 0.002193  loss_rpn_loc: 0.009701    time: 0.3923  last_time: 0.4602  data_time: 0.0142  last_data_time: 0.0242   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:24:18 d2.utils.events]:  eta: 0:16:30  iter: 2459  total_loss: 0.3051  loss_cls: 0.06327  loss_box_reg: 0.1866  loss_rpn_cls: 0.002411  loss_rpn_loc: 0.01679    time: 0.3922  last_time: 0.3588  data_time: 0.0114  last_data_time: 0.0135   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:24:26 d2.utils.events]:  eta: 0:16:22  iter: 2479  total_loss: 0.2892  loss_cls: 0.0645  loss_box_reg: 0.1975  loss_rpn_cls: 0.00181  loss_rpn_loc: 0.01211    time: 0.3921  last_time: 0.3888  data_time: 0.0114  last_data_time: 0.0125   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:24:34 d2.utils.events]:  eta: 0:16:14  iter: 2499  total_loss: 0.2846  loss_cls: 0.07436  loss_box_reg: 0.1888  loss_rpn_cls: 0.001198  loss_rpn_loc: 0.01698    time: 0.3921  last_time: 0.4450  data_time: 0.0091  last_data_time: 0.0059   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:24:42 d2.utils.events]:  eta: 0:16:06  iter: 2519  total_loss: 0.319  loss_cls: 0.06289  loss_box_reg: 0.2169  loss_rpn_cls: 0.00229  loss_rpn_loc: 0.007219    time: 0.3922  last_time: 0.3784  data_time: 0.0145  last_data_time: 0.0127   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:24:50 d2.utils.events]:  eta: 0:15:59  iter: 2539  total_loss: 0.3739  loss_cls: 0.08518  loss_box_reg: 0.2643  loss_rpn_cls: 0.001853  loss_rpn_loc: 0.0141    time: 0.3923  last_time: 0.3849  data_time: 0.0124  last_data_time: 0.0059   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:24:57 d2.utils.events]:  eta: 0:15:50  iter: 2559  total_loss: 0.3437  loss_cls: 0.06364  loss_box_reg: 0.2409  loss_rpn_cls: 0.0008234  loss_rpn_loc: 0.009611    time: 0.3922  last_time: 0.3541  data_time: 0.0093  last_data_time: 0.0132   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:25:05 d2.utils.events]:  eta: 0:15:42  iter: 2579  total_loss: 0.2884  loss_cls: 0.06697  loss_box_reg: 0.1941  loss_rpn_cls: 0.002891  loss_rpn_loc: 0.01324    time: 0.3922  last_time: 0.4488  data_time: 0.0106  last_data_time: 0.0181   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:25:13 d2.utils.events]:  eta: 0:15:35  iter: 2599  total_loss: 0.3016  loss_cls: 0.05356  loss_box_reg: 0.1897  loss_rpn_cls: 0.00322  loss_rpn_loc: 0.01457    time: 0.3922  last_time: 0.4557  data_time: 0.0088  last_data_time: 0.0067   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:25:21 d2.utils.events]:  eta: 0:15:27  iter: 2619  total_loss: 0.3306  loss_cls: 0.06538  loss_box_reg: 0.2377  loss_rpn_cls: 0.001767  loss_rpn_loc: 0.01357    time: 0.3923  last_time: 0.3760  data_time: 0.0122  last_data_time: 0.0059   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:25:29 d2.utils.events]:  eta: 0:15:19  iter: 2639  total_loss: 0.3453  loss_cls: 0.08135  loss_box_reg: 0.2238  loss_rpn_cls: 0.003059  loss_rpn_loc: 0.01246    time: 0.3923  last_time: 0.4659  data_time: 0.0127  last_data_time: 0.0259   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:25:37 d2.utils.events]:  eta: 0:15:12  iter: 2659  total_loss: 0.2681  loss_cls: 0.05331  loss_box_reg: 0.2064  loss_rpn_cls: 0.001478  loss_rpn_loc: 0.01132    time: 0.3924  last_time: 0.4434  data_time: 0.0091  last_data_time: 0.0058   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:25:45 d2.utils.events]:  eta: 0:15:04  iter: 2679  total_loss: 0.2844  loss_cls: 0.0609  loss_box_reg: 0.2007  loss_rpn_cls: 0.002304  loss_rpn_loc: 0.01067    time: 0.3925  last_time: 0.3948  data_time: 0.0099  last_data_time: 0.0118   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:25:53 d2.utils.events]:  eta: 0:14:56  iter: 2699  total_loss: 0.3247  loss_cls: 0.06757  loss_box_reg: 0.2223  loss_rpn_cls: 0.001043  loss_rpn_loc: 0.01217    time: 0.3924  last_time: 0.4024  data_time: 0.0087  last_data_time: 0.0173   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:26:01 d2.utils.events]:  eta: 0:14:48  iter: 2719  total_loss: 0.3801  loss_cls: 0.07412  loss_box_reg: 0.2515  loss_rpn_cls: 0.003365  loss_rpn_loc: 0.007982    time: 0.3925  last_time: 0.3765  data_time: 0.0134  last_data_time: 0.0124   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:26:09 d2.utils.events]:  eta: 0:14:40  iter: 2739  total_loss: 0.2819  loss_cls: 0.07145  loss_box_reg: 0.1949  loss_rpn_cls: 0.001564  loss_rpn_loc: 0.01306    time: 0.3925  last_time: 0.3770  data_time: 0.0115  last_data_time: 0.0074   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:26:17 d2.utils.events]:  eta: 0:14:32  iter: 2759  total_loss: 0.2686  loss_cls: 0.06849  loss_box_reg: 0.1696  loss_rpn_cls: 0.002801  loss_rpn_loc: 0.01376    time: 0.3924  last_time: 0.4431  data_time: 0.0087  last_data_time: 0.0053   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:26:25 d2.utils.events]:  eta: 0:14:24  iter: 2779  total_loss: 0.3093  loss_cls: 0.06939  loss_box_reg: 0.2365  loss_rpn_cls: 0.001508  loss_rpn_loc: 0.01095    time: 0.3925  last_time: 0.3871  data_time: 0.0128  last_data_time: 0.0198   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:26:32 d2.utils.events]:  eta: 0:14:16  iter: 2799  total_loss: 0.2711  loss_cls: 0.0557  loss_box_reg: 0.195  loss_rpn_cls: 0.002391  loss_rpn_loc: 0.01021    time: 0.3925  last_time: 0.4017  data_time: 0.0099  last_data_time: 0.0181   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:26:40 d2.utils.events]:  eta: 0:14:08  iter: 2819  total_loss: 0.2946  loss_cls: 0.06146  loss_box_reg: 0.1968  loss_rpn_cls: 0.003052  loss_rpn_loc: 0.01754    time: 0.3924  last_time: 0.3865  data_time: 0.0138  last_data_time: 0.0054   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:26:48 d2.utils.events]:  eta: 0:14:00  iter: 2839  total_loss: 0.2859  loss_cls: 0.06449  loss_box_reg: 0.1955  loss_rpn_cls: 0.001027  loss_rpn_loc: 0.01437    time: 0.3924  last_time: 0.3254  data_time: 0.0103  last_data_time: 0.0170   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:26:56 d2.utils.events]:  eta: 0:13:52  iter: 2859  total_loss: 0.2894  loss_cls: 0.06385  loss_box_reg: 0.2106  loss_rpn_cls: 0.001271  loss_rpn_loc: 0.01214    time: 0.3924  last_time: 0.4413  data_time: 0.0091  last_data_time: 0.0063   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:27:04 d2.utils.events]:  eta: 0:13:45  iter: 2879  total_loss: 0.2855  loss_cls: 0.06263  loss_box_reg: 0.1886  loss_rpn_cls: 0.002142  loss_rpn_loc: 0.01006    time: 0.3925  last_time: 0.3441  data_time: 0.0093  last_data_time: 0.0046   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:27:12 d2.utils.events]:  eta: 0:13:37  iter: 2899  total_loss: 0.3073  loss_cls: 0.05719  loss_box_reg: 0.2221  loss_rpn_cls: 0.001838  loss_rpn_loc: 0.009317    time: 0.3925  last_time: 0.4136  data_time: 0.0098  last_data_time: 0.0206   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:27:20 d2.utils.events]:  eta: 0:13:29  iter: 2919  total_loss: 0.2405  loss_cls: 0.04918  loss_box_reg: 0.1726  loss_rpn_cls: 0.001577  loss_rpn_loc: 0.01007    time: 0.3925  last_time: 0.4368  data_time: 0.0086  last_data_time: 0.0055   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:27:28 d2.utils.events]:  eta: 0:13:22  iter: 2939  total_loss: 0.2612  loss_cls: 0.05785  loss_box_reg: 0.1887  loss_rpn_cls: 0.00115  loss_rpn_loc: 0.009991    time: 0.3925  last_time: 0.3561  data_time: 0.0126  last_data_time: 0.0064   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:27:36 d2.utils.events]:  eta: 0:13:14  iter: 2959  total_loss: 0.2644  loss_cls: 0.05811  loss_box_reg: 0.1935  loss_rpn_cls: 0.001767  loss_rpn_loc: 0.01167    time: 0.3926  last_time: 0.2968  data_time: 0.0083  last_data_time: 0.0057   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:27:43 d2.utils.events]:  eta: 0:13:06  iter: 2979  total_loss: 0.2986  loss_cls: 0.05849  loss_box_reg: 0.2005  loss_rpn_cls: 0.002804  loss_rpn_loc: 0.01465    time: 0.3925  last_time: 0.3531  data_time: 0.0133  last_data_time: 0.0129   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:27:51 d2.utils.events]:  eta: 0:12:58  iter: 2999  total_loss: 0.2647  loss_cls: 0.05856  loss_box_reg: 0.1817  loss_rpn_cls: 0.002111  loss_rpn_loc: 0.009891    time: 0.3923  last_time: 0.3919  data_time: 0.0082  last_data_time: 0.0267   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:27:59 d2.utils.events]:  eta: 0:12:50  iter: 3019  total_loss: 0.31  loss_cls: 0.07253  loss_box_reg: 0.2059  loss_rpn_cls: 0.002129  loss_rpn_loc: 0.007896    time: 0.3923  last_time: 0.3884  data_time: 0.0128  last_data_time: 0.0055   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:28:06 d2.utils.events]:  eta: 0:12:42  iter: 3039  total_loss: 0.2738  loss_cls: 0.05364  loss_box_reg: 0.1889  loss_rpn_cls: 0.001622  loss_rpn_loc: 0.02252    time: 0.3924  last_time: 0.3928  data_time: 0.0106  last_data_time: 0.0115   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:28:15 d2.utils.events]:  eta: 0:12:34  iter: 3059  total_loss: 0.2987  loss_cls: 0.06284  loss_box_reg: 0.2101  loss_rpn_cls: 0.001632  loss_rpn_loc: 0.009904    time: 0.3924  last_time: 0.3882  data_time: 0.0082  last_data_time: 0.0055   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:28:22 d2.utils.events]:  eta: 0:12:27  iter: 3079  total_loss: 0.3356  loss_cls: 0.07405  loss_box_reg: 0.2303  loss_rpn_cls: 0.002784  loss_rpn_loc: 0.01588    time: 0.3924  last_time: 0.3704  data_time: 0.0097  last_data_time: 0.0055   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:28:30 d2.utils.events]:  eta: 0:12:19  iter: 3099  total_loss: 0.2762  loss_cls: 0.05873  loss_box_reg: 0.1779  loss_rpn_cls: 0.002712  loss_rpn_loc: 0.008732    time: 0.3923  last_time: 0.3738  data_time: 0.0090  last_data_time: 0.0283   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:28:38 d2.utils.events]:  eta: 0:12:11  iter: 3119  total_loss: 0.2641  loss_cls: 0.05455  loss_box_reg: 0.1855  loss_rpn_cls: 0.001317  loss_rpn_loc: 0.01678    time: 0.3924  last_time: 0.4393  data_time: 0.0121  last_data_time: 0.0064   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:28:46 d2.utils.events]:  eta: 0:12:04  iter: 3139  total_loss: 0.3002  loss_cls: 0.05357  loss_box_reg: 0.2054  loss_rpn_cls: 0.0008597  loss_rpn_loc: 0.007602    time: 0.3924  last_time: 0.3939  data_time: 0.0121  last_data_time: 0.0171   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:28:54 d2.utils.events]:  eta: 0:11:56  iter: 3159  total_loss: 0.2488  loss_cls: 0.05531  loss_box_reg: 0.174  loss_rpn_cls: 0.002133  loss_rpn_loc: 0.01427    time: 0.3924  last_time: 0.4396  data_time: 0.0063  last_data_time: 0.0062   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:29:02 d2.utils.events]:  eta: 0:11:48  iter: 3179  total_loss: 0.2885  loss_cls: 0.06103  loss_box_reg: 0.1987  loss_rpn_cls: 0.001981  loss_rpn_loc: 0.01064    time: 0.3925  last_time: 0.3911  data_time: 0.0087  last_data_time: 0.0053   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:29:10 d2.utils.events]:  eta: 0:11:40  iter: 3199  total_loss: 0.3004  loss_cls: 0.06362  loss_box_reg: 0.2192  loss_rpn_cls: 0.00259  loss_rpn_loc: 0.011    time: 0.3924  last_time: 0.4155  data_time: 0.0095  last_data_time: 0.0243   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:29:17 d2.utils.events]:  eta: 0:11:32  iter: 3219  total_loss: 0.2138  loss_cls: 0.03934  loss_box_reg: 0.1495  loss_rpn_cls: 0.0006906  loss_rpn_loc: 0.0186    time: 0.3925  last_time: 0.3707  data_time: 0.0124  last_data_time: 0.0055   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:29:25 d2.utils.events]:  eta: 0:11:24  iter: 3239  total_loss: 0.2296  loss_cls: 0.04308  loss_box_reg: 0.1658  loss_rpn_cls: 0.0008382  loss_rpn_loc: 0.008398    time: 0.3924  last_time: 0.2916  data_time: 0.0121  last_data_time: 0.0052   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:29:33 d2.utils.events]:  eta: 0:11:17  iter: 3259  total_loss: 0.278  loss_cls: 0.03892  loss_box_reg: 0.2058  loss_rpn_cls: 0.002423  loss_rpn_loc: 0.008733    time: 0.3924  last_time: 0.3193  data_time: 0.0085  last_data_time: 0.0118   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:29:41 d2.utils.events]:  eta: 0:11:09  iter: 3279  total_loss: 0.2609  loss_cls: 0.06488  loss_box_reg: 0.1871  loss_rpn_cls: 0.002743  loss_rpn_loc: 0.01166    time: 0.3926  last_time: 0.4390  data_time: 0.0162  last_data_time: 0.0050   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:29:49 d2.utils.events]:  eta: 0:11:01  iter: 3299  total_loss: 0.2769  loss_cls: 0.04748  loss_box_reg: 0.201  loss_rpn_cls: 0.002075  loss_rpn_loc: 0.008725    time: 0.3926  last_time: 0.3905  data_time: 0.0082  last_data_time: 0.0155   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:29:57 d2.utils.events]:  eta: 0:10:53  iter: 3319  total_loss: 0.2512  loss_cls: 0.06063  loss_box_reg: 0.1614  loss_rpn_cls: 0.001824  loss_rpn_loc: 0.009895    time: 0.3926  last_time: 0.4405  data_time: 0.0127  last_data_time: 0.0058   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:30:06 d2.utils.events]:  eta: 0:10:45  iter: 3339  total_loss: 0.2428  loss_cls: 0.05173  loss_box_reg: 0.174  loss_rpn_cls: 0.001259  loss_rpn_loc: 0.006114    time: 0.3927  last_time: 0.4584  data_time: 0.0138  last_data_time: 0.0160   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:30:13 d2.utils.events]:  eta: 0:10:38  iter: 3359  total_loss: 0.228  loss_cls: 0.05676  loss_box_reg: 0.1557  loss_rpn_cls: 0.0006966  loss_rpn_loc: 0.01343    time: 0.3927  last_time: 0.4396  data_time: 0.0086  last_data_time: 0.0055   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:30:21 d2.utils.events]:  eta: 0:10:30  iter: 3379  total_loss: 0.243  loss_cls: 0.04572  loss_box_reg: 0.162  loss_rpn_cls: 0.0009053  loss_rpn_loc: 0.0121    time: 0.3926  last_time: 0.3690  data_time: 0.0117  last_data_time: 0.0053   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:30:29 d2.utils.events]:  eta: 0:10:22  iter: 3399  total_loss: 0.1842  loss_cls: 0.03939  loss_box_reg: 0.1239  loss_rpn_cls: 0.001683  loss_rpn_loc: 0.01418    time: 0.3926  last_time: 0.4006  data_time: 0.0119  last_data_time: 0.0214   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:30:37 d2.utils.events]:  eta: 0:10:14  iter: 3419  total_loss: 0.2681  loss_cls: 0.05186  loss_box_reg: 0.1933  loss_rpn_cls: 0.0008496  loss_rpn_loc: 0.0117    time: 0.3926  last_time: 0.3931  data_time: 0.0125  last_data_time: 0.0056   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:30:45 d2.utils.events]:  eta: 0:10:06  iter: 3439  total_loss: 0.2744  loss_cls: 0.05949  loss_box_reg: 0.2053  loss_rpn_cls: 0.001777  loss_rpn_loc: 0.009735    time: 0.3926  last_time: 0.4608  data_time: 0.0089  last_data_time: 0.0179   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:30:52 d2.utils.events]:  eta: 0:09:58  iter: 3459  total_loss: 0.256  loss_cls: 0.04738  loss_box_reg: 0.1737  loss_rpn_cls: 0.001635  loss_rpn_loc: 0.01148    time: 0.3926  last_time: 0.3501  data_time: 0.0119  last_data_time: 0.0125   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:31:00 d2.utils.events]:  eta: 0:09:51  iter: 3479  total_loss: 0.2636  loss_cls: 0.05352  loss_box_reg: 0.1792  loss_rpn_cls: 0.0012  loss_rpn_loc: 0.009822    time: 0.3926  last_time: 0.3893  data_time: 0.0131  last_data_time: 0.0118   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:31:08 d2.utils.events]:  eta: 0:09:43  iter: 3499  total_loss: 0.2312  loss_cls: 0.05421  loss_box_reg: 0.1685  loss_rpn_cls: 0.001083  loss_rpn_loc: 0.007971    time: 0.3925  last_time: 0.3862  data_time: 0.0095  last_data_time: 0.0055   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:31:16 d2.utils.events]:  eta: 0:09:35  iter: 3519  total_loss: 0.2561  loss_cls: 0.04538  loss_box_reg: 0.1749  loss_rpn_cls: 0.002302  loss_rpn_loc: 0.01171    time: 0.3927  last_time: 0.4449  data_time: 0.0136  last_data_time: 0.0127   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:31:24 d2.utils.events]:  eta: 0:09:27  iter: 3539  total_loss: 0.2098  loss_cls: 0.04446  loss_box_reg: 0.1431  loss_rpn_cls: 0.001175  loss_rpn_loc: 0.01388    time: 0.3927  last_time: 0.3578  data_time: 0.0111  last_data_time: 0.0055   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:31:32 d2.utils.events]:  eta: 0:09:19  iter: 3559  total_loss: 0.2867  loss_cls: 0.05786  loss_box_reg: 0.2173  loss_rpn_cls: 0.0006766  loss_rpn_loc: 0.005954    time: 0.3926  last_time: 0.2929  data_time: 0.0101  last_data_time: 0.0055   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:31:40 d2.utils.events]:  eta: 0:09:12  iter: 3579  total_loss: 0.2399  loss_cls: 0.04542  loss_box_reg: 0.1813  loss_rpn_cls: 0.0006758  loss_rpn_loc: 0.01111    time: 0.3926  last_time: 0.3916  data_time: 0.0124  last_data_time: 0.0088   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:31:48 d2.utils.events]:  eta: 0:09:04  iter: 3599  total_loss: 0.2536  loss_cls: 0.05673  loss_box_reg: 0.1633  loss_rpn_cls: 0.001145  loss_rpn_loc: 0.01219    time: 0.3927  last_time: 0.4061  data_time: 0.0086  last_data_time: 0.0157   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:31:56 d2.utils.events]:  eta: 0:08:56  iter: 3619  total_loss: 0.2663  loss_cls: 0.05626  loss_box_reg: 0.174  loss_rpn_cls: 0.000533  loss_rpn_loc: 0.0103    time: 0.3927  last_time: 0.3900  data_time: 0.0114  last_data_time: 0.0127   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:32:03 d2.utils.events]:  eta: 0:08:48  iter: 3639  total_loss: 0.288  loss_cls: 0.0548  loss_box_reg: 0.1851  loss_rpn_cls: 0.00134  loss_rpn_loc: 0.0145    time: 0.3927  last_time: 0.4461  data_time: 0.0114  last_data_time: 0.0115   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:32:11 d2.utils.events]:  eta: 0:08:40  iter: 3659  total_loss: 0.2571  loss_cls: 0.03415  loss_box_reg: 0.2111  loss_rpn_cls: 0.00224  loss_rpn_loc: 0.009156    time: 0.3926  last_time: 0.4379  data_time: 0.0079  last_data_time: 0.0054   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:32:19 d2.utils.events]:  eta: 0:08:33  iter: 3679  total_loss: 0.2478  loss_cls: 0.04917  loss_box_reg: 0.158  loss_rpn_cls: 0.001313  loss_rpn_loc: 0.007802    time: 0.3927  last_time: 0.3718  data_time: 0.0093  last_data_time: 0.0055   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:32:27 d2.utils.events]:  eta: 0:08:25  iter: 3699  total_loss: 0.2345  loss_cls: 0.04744  loss_box_reg: 0.1555  loss_rpn_cls: 0.0008504  loss_rpn_loc: 0.01655    time: 0.3927  last_time: 0.4526  data_time: 0.0100  last_data_time: 0.0154   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:32:35 d2.utils.events]:  eta: 0:08:17  iter: 3719  total_loss: 0.1814  loss_cls: 0.03403  loss_box_reg: 0.1243  loss_rpn_cls: 0.001512  loss_rpn_loc: 0.0122    time: 0.3928  last_time: 0.3883  data_time: 0.0123  last_data_time: 0.0061   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:32:43 d2.utils.events]:  eta: 0:08:09  iter: 3739  total_loss: 0.2652  loss_cls: 0.04335  loss_box_reg: 0.1982  loss_rpn_cls: 0.001106  loss_rpn_loc: 0.01413    time: 0.3929  last_time: 0.3727  data_time: 0.0125  last_data_time: 0.0059   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:32:51 d2.utils.events]:  eta: 0:08:01  iter: 3759  total_loss: 0.2664  loss_cls: 0.05013  loss_box_reg: 0.1774  loss_rpn_cls: 0.001804  loss_rpn_loc: 0.007531    time: 0.3927  last_time: 0.4424  data_time: 0.0082  last_data_time: 0.0117   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:32:58 d2.utils.events]:  eta: 0:07:54  iter: 3779  total_loss: 0.2083  loss_cls: 0.0389  loss_box_reg: 0.1537  loss_rpn_cls: 0.001313  loss_rpn_loc: 0.009463    time: 0.3926  last_time: 0.4460  data_time: 0.0137  last_data_time: 0.0053   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:33:06 d2.utils.events]:  eta: 0:07:46  iter: 3799  total_loss: 0.2393  loss_cls: 0.04508  loss_box_reg: 0.1734  loss_rpn_cls: 0.001287  loss_rpn_loc: 0.007922    time: 0.3926  last_time: 0.3506  data_time: 0.0093  last_data_time: 0.0057   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:33:14 d2.utils.events]:  eta: 0:07:38  iter: 3819  total_loss: 0.2248  loss_cls: 0.04504  loss_box_reg: 0.1559  loss_rpn_cls: 0.001323  loss_rpn_loc: 0.01081    time: 0.3925  last_time: 0.3762  data_time: 0.0134  last_data_time: 0.0066   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:33:21 d2.utils.events]:  eta: 0:07:30  iter: 3839  total_loss: 0.2244  loss_cls: 0.04765  loss_box_reg: 0.1718  loss_rpn_cls: 0.001344  loss_rpn_loc: 0.00712    time: 0.3925  last_time: 0.2986  data_time: 0.0096  last_data_time: 0.0059   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:33:29 d2.utils.events]:  eta: 0:07:22  iter: 3859  total_loss: 0.2032  loss_cls: 0.04729  loss_box_reg: 0.1374  loss_rpn_cls: 0.001063  loss_rpn_loc: 0.00618    time: 0.3924  last_time: 0.4406  data_time: 0.0065  last_data_time: 0.0055   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:33:37 d2.utils.events]:  eta: 0:07:14  iter: 3879  total_loss: 0.1967  loss_cls: 0.04117  loss_box_reg: 0.1257  loss_rpn_cls: 0.0008451  loss_rpn_loc: 0.01004    time: 0.3925  last_time: 0.4443  data_time: 0.0140  last_data_time: 0.0053   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:33:45 d2.utils.events]:  eta: 0:07:07  iter: 3899  total_loss: 0.2535  loss_cls: 0.05036  loss_box_reg: 0.1728  loss_rpn_cls: 0.002812  loss_rpn_loc: 0.01344    time: 0.3925  last_time: 0.3142  data_time: 0.0080  last_data_time: 0.0055   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:33:53 d2.utils.events]:  eta: 0:06:59  iter: 3919  total_loss: 0.2406  loss_cls: 0.03357  loss_box_reg: 0.1867  loss_rpn_cls: 0.002249  loss_rpn_loc: 0.01863    time: 0.3926  last_time: 0.3520  data_time: 0.0100  last_data_time: 0.0128   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:34:01 d2.utils.events]:  eta: 0:06:51  iter: 3939  total_loss: 0.2098  loss_cls: 0.03938  loss_box_reg: 0.1604  loss_rpn_cls: 0.0004549  loss_rpn_loc: 0.006301    time: 0.3925  last_time: 0.3982  data_time: 0.0105  last_data_time: 0.0058   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:34:09 d2.utils.events]:  eta: 0:06:43  iter: 3959  total_loss: 0.2294  loss_cls: 0.04219  loss_box_reg: 0.1646  loss_rpn_cls: 0.00259  loss_rpn_loc: 0.01324    time: 0.3926  last_time: 0.3162  data_time: 0.0090  last_data_time: 0.0057   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:34:17 d2.utils.events]:  eta: 0:06:36  iter: 3979  total_loss: 0.2142  loss_cls: 0.04055  loss_box_reg: 0.1633  loss_rpn_cls: 0.001118  loss_rpn_loc: 0.01685    time: 0.3926  last_time: 0.3890  data_time: 0.0119  last_data_time: 0.0059   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:34:25 d2.utils.events]:  eta: 0:06:28  iter: 3999  total_loss: 0.2061  loss_cls: 0.03941  loss_box_reg: 0.1316  loss_rpn_cls: 0.000901  loss_rpn_loc: 0.01057    time: 0.3926  last_time: 0.3979  data_time: 0.0076  last_data_time: 0.0064   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:34:32 d2.utils.events]:  eta: 0:06:20  iter: 4019  total_loss: 0.2307  loss_cls: 0.04128  loss_box_reg: 0.1778  loss_rpn_cls: 0.0009002  loss_rpn_loc: 0.008551    time: 0.3926  last_time: 0.3142  data_time: 0.0080  last_data_time: 0.0062   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:34:40 d2.utils.events]:  eta: 0:06:12  iter: 4039  total_loss: 0.23  loss_cls: 0.05448  loss_box_reg: 0.1702  loss_rpn_cls: 0.0004201  loss_rpn_loc: 0.005493    time: 0.3926  last_time: 0.4060  data_time: 0.0112  last_data_time: 0.0148   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:34:48 d2.utils.events]:  eta: 0:06:05  iter: 4059  total_loss: 0.231  loss_cls: 0.04738  loss_box_reg: 0.1711  loss_rpn_cls: 0.0006432  loss_rpn_loc: 0.006986    time: 0.3925  last_time: 0.3706  data_time: 0.0075  last_data_time: 0.0061   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:34:56 d2.utils.events]:  eta: 0:05:57  iter: 4079  total_loss: 0.2372  loss_cls: 0.05029  loss_box_reg: 0.1596  loss_rpn_cls: 0.0008475  loss_rpn_loc: 0.01288    time: 0.3926  last_time: 0.4440  data_time: 0.0121  last_data_time: 0.0057   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:35:04 d2.utils.events]:  eta: 0:05:49  iter: 4099  total_loss: 0.1953  loss_cls: 0.03316  loss_box_reg: 0.1333  loss_rpn_cls: 0.001662  loss_rpn_loc: 0.01261    time: 0.3926  last_time: 0.3010  data_time: 0.0084  last_data_time: 0.0053   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:35:12 d2.utils.events]:  eta: 0:05:41  iter: 4119  total_loss: 0.202  loss_cls: 0.03679  loss_box_reg: 0.136  loss_rpn_cls: 0.001167  loss_rpn_loc: 0.01067    time: 0.3926  last_time: 0.3703  data_time: 0.0115  last_data_time: 0.0056   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:35:20 d2.utils.events]:  eta: 0:05:34  iter: 4139  total_loss: 0.2104  loss_cls: 0.04083  loss_box_reg: 0.1456  loss_rpn_cls: 0.001706  loss_rpn_loc: 0.01169    time: 0.3927  last_time: 0.4084  data_time: 0.0128  last_data_time: 0.0264   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:35:28 d2.utils.events]:  eta: 0:05:26  iter: 4159  total_loss: 0.2507  loss_cls: 0.05068  loss_box_reg: 0.1848  loss_rpn_cls: 0.001112  loss_rpn_loc: 0.008494    time: 0.3926  last_time: 0.4493  data_time: 0.0087  last_data_time: 0.0192   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:35:35 d2.utils.events]:  eta: 0:05:18  iter: 4179  total_loss: 0.2001  loss_cls: 0.03485  loss_box_reg: 0.1436  loss_rpn_cls: 0.0008139  loss_rpn_loc: 0.007396    time: 0.3926  last_time: 0.3782  data_time: 0.0130  last_data_time: 0.0126   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:35:43 d2.utils.events]:  eta: 0:05:10  iter: 4199  total_loss: 0.2033  loss_cls: 0.04205  loss_box_reg: 0.1414  loss_rpn_cls: 0.0004295  loss_rpn_loc: 0.009105    time: 0.3926  last_time: 0.4543  data_time: 0.0066  last_data_time: 0.0105   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:35:52 d2.utils.events]:  eta: 0:05:03  iter: 4219  total_loss: 0.2104  loss_cls: 0.03672  loss_box_reg: 0.1366  loss_rpn_cls: 0.00109  loss_rpn_loc: 0.01403    time: 0.3927  last_time: 0.4502  data_time: 0.0145  last_data_time: 0.0180   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:36:00 d2.utils.events]:  eta: 0:04:55  iter: 4239  total_loss: 0.2316  loss_cls: 0.04556  loss_box_reg: 0.1663  loss_rpn_cls: 0.001013  loss_rpn_loc: 0.01381    time: 0.3928  last_time: 0.3907  data_time: 0.0150  last_data_time: 0.0238   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:36:07 d2.utils.events]:  eta: 0:04:47  iter: 4259  total_loss: 0.1716  loss_cls: 0.04361  loss_box_reg: 0.1127  loss_rpn_cls: 0.001408  loss_rpn_loc: 0.007529    time: 0.3927  last_time: 0.4442  data_time: 0.0086  last_data_time: 0.0061   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:36:15 d2.utils.events]:  eta: 0:04:39  iter: 4279  total_loss: 0.18  loss_cls: 0.04034  loss_box_reg: 0.1452  loss_rpn_cls: 0.0003596  loss_rpn_loc: 0.008653    time: 0.3927  last_time: 0.3847  data_time: 0.0079  last_data_time: 0.0053   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:36:23 d2.utils.events]:  eta: 0:04:32  iter: 4299  total_loss: 0.1867  loss_cls: 0.03877  loss_box_reg: 0.1237  loss_rpn_cls: 0.0006366  loss_rpn_loc: 0.01314    time: 0.3928  last_time: 0.4082  data_time: 0.0094  last_data_time: 0.0170   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:36:31 d2.utils.events]:  eta: 0:04:24  iter: 4319  total_loss: 0.2496  loss_cls: 0.04692  loss_box_reg: 0.1781  loss_rpn_cls: 0.00067  loss_rpn_loc: 0.008903    time: 0.3928  last_time: 0.3949  data_time: 0.0100  last_data_time: 0.0050   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:36:39 d2.utils.events]:  eta: 0:04:16  iter: 4339  total_loss: 0.1886  loss_cls: 0.0304  loss_box_reg: 0.1439  loss_rpn_cls: 0.0004632  loss_rpn_loc: 0.008227    time: 0.3928  last_time: 0.3675  data_time: 0.0141  last_data_time: 0.0049   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:36:47 d2.utils.events]:  eta: 0:04:08  iter: 4359  total_loss: 0.1921  loss_cls: 0.03677  loss_box_reg: 0.1289  loss_rpn_cls: 0.0008292  loss_rpn_loc: 0.01063    time: 0.3928  last_time: 0.3859  data_time: 0.0071  last_data_time: 0.0061   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:36:55 d2.utils.events]:  eta: 0:04:00  iter: 4379  total_loss: 0.2161  loss_cls: 0.03889  loss_box_reg: 0.1627  loss_rpn_cls: 0.0008946  loss_rpn_loc: 0.007918    time: 0.3927  last_time: 0.3697  data_time: 0.0136  last_data_time: 0.0056   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:37:02 d2.utils.events]:  eta: 0:03:53  iter: 4399  total_loss: 0.2069  loss_cls: 0.04933  loss_box_reg: 0.1433  loss_rpn_cls: 0.0006697  loss_rpn_loc: 0.0103    time: 0.3927  last_time: 0.3345  data_time: 0.0085  last_data_time: 0.0175   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:37:10 d2.utils.events]:  eta: 0:03:45  iter: 4419  total_loss: 0.209  loss_cls: 0.0364  loss_box_reg: 0.1419  loss_rpn_cls: 0.001593  loss_rpn_loc: 0.008292    time: 0.3927  last_time: 0.3817  data_time: 0.0117  last_data_time: 0.0059   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:37:18 d2.utils.events]:  eta: 0:03:37  iter: 4439  total_loss: 0.1688  loss_cls: 0.03099  loss_box_reg: 0.1239  loss_rpn_cls: 0.0006727  loss_rpn_loc: 0.00833    time: 0.3927  last_time: 0.4358  data_time: 0.0119  last_data_time: 0.0061   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:37:26 d2.utils.events]:  eta: 0:03:29  iter: 4459  total_loss: 0.2497  loss_cls: 0.0453  loss_box_reg: 0.1752  loss_rpn_cls: 0.0007554  loss_rpn_loc: 0.008592    time: 0.3926  last_time: 0.3767  data_time: 0.0100  last_data_time: 0.0126   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:37:33 d2.utils.events]:  eta: 0:03:21  iter: 4479  total_loss: 0.2387  loss_cls: 0.05304  loss_box_reg: 0.1579  loss_rpn_cls: 0.001171  loss_rpn_loc: 0.01085    time: 0.3926  last_time: 0.3520  data_time: 0.0169  last_data_time: 0.0142   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:37:41 d2.utils.events]:  eta: 0:03:14  iter: 4499  total_loss: 0.1943  loss_cls: 0.03692  loss_box_reg: 0.1553  loss_rpn_cls: 0.0009888  loss_rpn_loc: 0.0131    time: 0.3926  last_time: 0.3767  data_time: 0.0081  last_data_time: 0.0064   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:37:49 d2.utils.events]:  eta: 0:03:06  iter: 4519  total_loss: 0.2166  loss_cls: 0.04929  loss_box_reg: 0.1536  loss_rpn_cls: 0.001527  loss_rpn_loc: 0.006051    time: 0.3927  last_time: 0.3741  data_time: 0.0119  last_data_time: 0.0057   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:37:57 d2.utils.events]:  eta: 0:02:58  iter: 4539  total_loss: 0.2158  loss_cls: 0.0392  loss_box_reg: 0.1442  loss_rpn_cls: 0.0023  loss_rpn_loc: 0.008798    time: 0.3927  last_time: 0.2989  data_time: 0.0093  last_data_time: 0.0052   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:38:05 d2.utils.events]:  eta: 0:02:50  iter: 4559  total_loss: 0.1896  loss_cls: 0.04136  loss_box_reg: 0.1278  loss_rpn_cls: 0.0009174  loss_rpn_loc: 0.006646    time: 0.3926  last_time: 0.3891  data_time: 0.0087  last_data_time: 0.0050   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:38:13 d2.utils.events]:  eta: 0:02:43  iter: 4579  total_loss: 0.1806  loss_cls: 0.02958  loss_box_reg: 0.1314  loss_rpn_cls: 0.00198  loss_rpn_loc: 0.009566    time: 0.3926  last_time: 0.3515  data_time: 0.0133  last_data_time: 0.0056   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:38:21 d2.utils.events]:  eta: 0:02:35  iter: 4599  total_loss: 0.1841  loss_cls: 0.0326  loss_box_reg: 0.1199  loss_rpn_cls: 0.001369  loss_rpn_loc: 0.01394    time: 0.3926  last_time: 0.3589  data_time: 0.0089  last_data_time: 0.0134   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:38:28 d2.utils.events]:  eta: 0:02:27  iter: 4619  total_loss: 0.1914  loss_cls: 0.04293  loss_box_reg: 0.1364  loss_rpn_cls: 0.001064  loss_rpn_loc: 0.006065    time: 0.3926  last_time: 0.4394  data_time: 0.0099  last_data_time: 0.0054   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:38:36 d2.utils.events]:  eta: 0:02:19  iter: 4639  total_loss: 0.202  loss_cls: 0.03761  loss_box_reg: 0.145  loss_rpn_cls: 0.0008134  loss_rpn_loc: 0.009307    time: 0.3926  last_time: 0.4064  data_time: 0.0119  last_data_time: 0.0180   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:38:44 d2.utils.events]:  eta: 0:02:11  iter: 4659  total_loss: 0.1618  loss_cls: 0.03109  loss_box_reg: 0.1033  loss_rpn_cls: 0.0005073  loss_rpn_loc: 0.009454    time: 0.3925  last_time: 0.4421  data_time: 0.0089  last_data_time: 0.0046   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:38:52 d2.utils.events]:  eta: 0:02:04  iter: 4679  total_loss: 0.1724  loss_cls: 0.04196  loss_box_reg: 0.1124  loss_rpn_cls: 0.0009647  loss_rpn_loc: 0.01084    time: 0.3926  last_time: 0.2929  data_time: 0.0099  last_data_time: 0.0058   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:39:00 d2.utils.events]:  eta: 0:01:56  iter: 4699  total_loss: 0.1836  loss_cls: 0.03803  loss_box_reg: 0.1349  loss_rpn_cls: 0.001431  loss_rpn_loc: 0.006844    time: 0.3925  last_time: 0.3998  data_time: 0.0098  last_data_time: 0.0063   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:39:08 d2.utils.events]:  eta: 0:01:48  iter: 4719  total_loss: 0.1721  loss_cls: 0.03385  loss_box_reg: 0.1146  loss_rpn_cls: 0.0008522  loss_rpn_loc: 0.0165    time: 0.3926  last_time: 0.3503  data_time: 0.0119  last_data_time: 0.0060   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:39:16 d2.utils.events]:  eta: 0:01:40  iter: 4739  total_loss: 0.1611  loss_cls: 0.03224  loss_box_reg: 0.1092  loss_rpn_cls: 0.0008313  loss_rpn_loc: 0.007768    time: 0.3926  last_time: 0.3757  data_time: 0.0147  last_data_time: 0.0144   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:39:24 d2.utils.events]:  eta: 0:01:33  iter: 4759  total_loss: 0.1901  loss_cls: 0.03663  loss_box_reg: 0.1239  loss_rpn_cls: 0.000825  loss_rpn_loc: 0.0103    time: 0.3926  last_time: 0.3978  data_time: 0.0079  last_data_time: 0.0188   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:39:32 d2.utils.events]:  eta: 0:01:25  iter: 4779  total_loss: 0.1973  loss_cls: 0.0355  loss_box_reg: 0.1376  loss_rpn_cls: 0.0003777  loss_rpn_loc: 0.01113    time: 0.3927  last_time: 0.3483  data_time: 0.0136  last_data_time: 0.0052   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:39:40 d2.utils.events]:  eta: 0:01:17  iter: 4799  total_loss: 0.1835  loss_cls: 0.03527  loss_box_reg: 0.1273  loss_rpn_cls: 0.001394  loss_rpn_loc: 0.01134    time: 0.3927  last_time: 0.4638  data_time: 0.0136  last_data_time: 0.0266   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:39:48 d2.utils.events]:  eta: 0:01:09  iter: 4819  total_loss: 0.2066  loss_cls: 0.04237  loss_box_reg: 0.1347  loss_rpn_cls: 0.0007026  loss_rpn_loc: 0.01143    time: 0.3928  last_time: 0.3549  data_time: 0.0124  last_data_time: 0.0140   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:39:56 d2.utils.events]:  eta: 0:01:02  iter: 4839  total_loss: 0.1758  loss_cls: 0.03276  loss_box_reg: 0.1266  loss_rpn_cls: 0.001142  loss_rpn_loc: 0.007436    time: 0.3928  last_time: 0.4408  data_time: 0.0111  last_data_time: 0.0050   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:40:04 d2.utils.events]:  eta: 0:00:54  iter: 4859  total_loss: 0.2027  loss_cls: 0.04302  loss_box_reg: 0.136  loss_rpn_cls: 0.00135  loss_rpn_loc: 0.009141    time: 0.3928  last_time: 0.3009  data_time: 0.0089  last_data_time: 0.0133   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:40:12 d2.utils.events]:  eta: 0:00:46  iter: 4879  total_loss: 0.1608  loss_cls: 0.03403  loss_box_reg: 0.1177  loss_rpn_cls: 0.000839  loss_rpn_loc: 0.009671    time: 0.3928  last_time: 0.3914  data_time: 0.0107  last_data_time: 0.0131   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:40:19 d2.utils.events]:  eta: 0:00:38  iter: 4899  total_loss: 0.1758  loss_cls: 0.03452  loss_box_reg: 0.1388  loss_rpn_cls: 0.0004657  loss_rpn_loc: 0.005701    time: 0.3927  last_time: 0.3791  data_time: 0.0074  last_data_time: 0.0056   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:40:27 d2.utils.events]:  eta: 0:00:31  iter: 4919  total_loss: 0.2036  loss_cls: 0.04661  loss_box_reg: 0.1432  loss_rpn_cls: 0.001398  loss_rpn_loc: 0.008586    time: 0.3927  last_time: 0.3860  data_time: 0.0109  last_data_time: 0.0166   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:40:35 d2.utils.events]:  eta: 0:00:23  iter: 4939  total_loss: 0.1717  loss_cls: 0.03214  loss_box_reg: 0.1211  loss_rpn_cls: 0.0005406  loss_rpn_loc: 0.01275    time: 0.3928  last_time: 0.4380  data_time: 0.0108  last_data_time: 0.0059   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:40:43 d2.utils.events]:  eta: 0:00:15  iter: 4959  total_loss: 0.1784  loss_cls: 0.0281  loss_box_reg: 0.1284  loss_rpn_cls: 0.001077  loss_rpn_loc: 0.01239    time: 0.3927  last_time: 0.3550  data_time: 0.0103  last_data_time: 0.0121   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:40:51 d2.utils.events]:  eta: 0:00:07  iter: 4979  total_loss: 0.1864  loss_cls: 0.03563  loss_box_reg: 0.1412  loss_rpn_cls: 0.0005689  loss_rpn_loc: 0.006398    time: 0.3928  last_time: 0.3530  data_time: 0.0156  last_data_time: 0.0053   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:41:06 d2.utils.events]:  eta: 0:00:00  iter: 4999  total_loss: 0.1933  loss_cls: 0.04491  loss_box_reg: 0.1321  loss_rpn_cls: 0.0006892  loss_rpn_loc: 0.007487    time: 0.3927  last_time: 0.4664  data_time: 0.0104  last_data_time: 0.0255   lr: 0.00025  max_mem: 3022M\n",
            "[01/02 15:41:06 d2.engine.hooks]: Overall training speed: 4998 iterations in 0:32:42 (0.3927 s / it)\n",
            "[01/02 15:41:06 d2.engine.hooks]: Total training time: 0:33:26 (0:00:43 on hooks)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "# Inisialisasi konfigurasi model\n",
        "cfg = get_cfg()\n",
        "cfg.MODEL.WEIGHTS = \"/content/output/model_final.pth\"  # Gantilah dengan path ke file model yang telah Anda simpan\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Threshold skor untuk deteksi\n",
        "cfg.DATASETS.TEST = (\"custom_dataset_val\",)  # Gantilah dengan dataset validasi Anda\n",
        "\n",
        "# Inisialisasi predictor\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Path gambar yang akan diuji\n",
        "image = cv2.imread(\"/content/dataset/photos/zebracross83.jpg\")   # Gantilah dengan path ke gambar yang akan diuji\n",
        "\n",
        "# Melakukan prediksi\n",
        "outputs = predictor(image)\n",
        "\n",
        "# Tampilkan hasil prediksi\n",
        "print(outputs[\"instances\"].pred_classes)\n",
        "print(outputs[\"instances\"].pred_boxes)\n",
        "# ... tambahkan informasi lain yang ingin Anda lihat\n",
        "\n",
        "# Mendapatkan metadata (kategori, warna, dsb.)\n",
        "metadata = MetadataCatalog.get(cfg.DATASETS.TEST[0])\n",
        "print(\"Labels:\", metadata.thing_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J9JwiAF2-IwZ",
        "outputId": "229cd3e1-0741-4d81-ae72-bcaf06cc5a5b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01/02 17:03:03 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /content/output/model_final.pth ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'proposal_generator.rpn_head.conv.weight' to the model due to incompatible shapes: (256, 256, 3, 3) in the checkpoint but (1024, 1024, 3, 3) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'proposal_generator.rpn_head.conv.bias' to the model due to incompatible shapes: (256,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (3, 256, 1, 1) in the checkpoint but (15, 1024, 1, 1) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (3,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (12, 256, 1, 1) in the checkpoint but (60, 1024, 1, 1) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (12,) in the checkpoint but (60,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (5, 1024) in the checkpoint but (81, 2048) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (5,) in the checkpoint but (81,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (16, 1024) in the checkpoint but (320, 2048) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (16,) in the checkpoint but (320,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "backbone.res2.0.conv1.norm.{bias, weight}\n",
            "backbone.res2.0.conv1.weight\n",
            "backbone.res2.0.conv2.norm.{bias, weight}\n",
            "backbone.res2.0.conv2.weight\n",
            "backbone.res2.0.conv3.norm.{bias, weight}\n",
            "backbone.res2.0.conv3.weight\n",
            "backbone.res2.0.shortcut.norm.{bias, weight}\n",
            "backbone.res2.0.shortcut.weight\n",
            "backbone.res2.1.conv1.norm.{bias, weight}\n",
            "backbone.res2.1.conv1.weight\n",
            "backbone.res2.1.conv2.norm.{bias, weight}\n",
            "backbone.res2.1.conv2.weight\n",
            "backbone.res2.1.conv3.norm.{bias, weight}\n",
            "backbone.res2.1.conv3.weight\n",
            "backbone.res2.2.conv1.norm.{bias, weight}\n",
            "backbone.res2.2.conv1.weight\n",
            "backbone.res2.2.conv2.norm.{bias, weight}\n",
            "backbone.res2.2.conv2.weight\n",
            "backbone.res2.2.conv3.norm.{bias, weight}\n",
            "backbone.res2.2.conv3.weight\n",
            "backbone.res3.0.conv1.norm.{bias, weight}\n",
            "backbone.res3.0.conv1.weight\n",
            "backbone.res3.0.conv2.norm.{bias, weight}\n",
            "backbone.res3.0.conv2.weight\n",
            "backbone.res3.0.conv3.norm.{bias, weight}\n",
            "backbone.res3.0.conv3.weight\n",
            "backbone.res3.0.shortcut.norm.{bias, weight}\n",
            "backbone.res3.0.shortcut.weight\n",
            "backbone.res3.1.conv1.norm.{bias, weight}\n",
            "backbone.res3.1.conv1.weight\n",
            "backbone.res3.1.conv2.norm.{bias, weight}\n",
            "backbone.res3.1.conv2.weight\n",
            "backbone.res3.1.conv3.norm.{bias, weight}\n",
            "backbone.res3.1.conv3.weight\n",
            "backbone.res3.2.conv1.norm.{bias, weight}\n",
            "backbone.res3.2.conv1.weight\n",
            "backbone.res3.2.conv2.norm.{bias, weight}\n",
            "backbone.res3.2.conv2.weight\n",
            "backbone.res3.2.conv3.norm.{bias, weight}\n",
            "backbone.res3.2.conv3.weight\n",
            "backbone.res3.3.conv1.norm.{bias, weight}\n",
            "backbone.res3.3.conv1.weight\n",
            "backbone.res3.3.conv2.norm.{bias, weight}\n",
            "backbone.res3.3.conv2.weight\n",
            "backbone.res3.3.conv3.norm.{bias, weight}\n",
            "backbone.res3.3.conv3.weight\n",
            "backbone.res4.0.conv1.norm.{bias, weight}\n",
            "backbone.res4.0.conv1.weight\n",
            "backbone.res4.0.conv2.norm.{bias, weight}\n",
            "backbone.res4.0.conv2.weight\n",
            "backbone.res4.0.conv3.norm.{bias, weight}\n",
            "backbone.res4.0.conv3.weight\n",
            "backbone.res4.0.shortcut.norm.{bias, weight}\n",
            "backbone.res4.0.shortcut.weight\n",
            "backbone.res4.1.conv1.norm.{bias, weight}\n",
            "backbone.res4.1.conv1.weight\n",
            "backbone.res4.1.conv2.norm.{bias, weight}\n",
            "backbone.res4.1.conv2.weight\n",
            "backbone.res4.1.conv3.norm.{bias, weight}\n",
            "backbone.res4.1.conv3.weight\n",
            "backbone.res4.2.conv1.norm.{bias, weight}\n",
            "backbone.res4.2.conv1.weight\n",
            "backbone.res4.2.conv2.norm.{bias, weight}\n",
            "backbone.res4.2.conv2.weight\n",
            "backbone.res4.2.conv3.norm.{bias, weight}\n",
            "backbone.res4.2.conv3.weight\n",
            "backbone.res4.3.conv1.norm.{bias, weight}\n",
            "backbone.res4.3.conv1.weight\n",
            "backbone.res4.3.conv2.norm.{bias, weight}\n",
            "backbone.res4.3.conv2.weight\n",
            "backbone.res4.3.conv3.norm.{bias, weight}\n",
            "backbone.res4.3.conv3.weight\n",
            "backbone.res4.4.conv1.norm.{bias, weight}\n",
            "backbone.res4.4.conv1.weight\n",
            "backbone.res4.4.conv2.norm.{bias, weight}\n",
            "backbone.res4.4.conv2.weight\n",
            "backbone.res4.4.conv3.norm.{bias, weight}\n",
            "backbone.res4.4.conv3.weight\n",
            "backbone.res4.5.conv1.norm.{bias, weight}\n",
            "backbone.res4.5.conv1.weight\n",
            "backbone.res4.5.conv2.norm.{bias, weight}\n",
            "backbone.res4.5.conv2.weight\n",
            "backbone.res4.5.conv3.norm.{bias, weight}\n",
            "backbone.res4.5.conv3.weight\n",
            "backbone.stem.conv1.norm.{bias, weight}\n",
            "backbone.stem.conv1.weight\n",
            "proposal_generator.rpn_head.anchor_deltas.{bias, weight}\n",
            "proposal_generator.rpn_head.conv.{bias, weight}\n",
            "proposal_generator.rpn_head.objectness_logits.{bias, weight}\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n",
            "roi_heads.res5.0.conv1.norm.{bias, weight}\n",
            "roi_heads.res5.0.conv1.weight\n",
            "roi_heads.res5.0.conv2.norm.{bias, weight}\n",
            "roi_heads.res5.0.conv2.weight\n",
            "roi_heads.res5.0.conv3.norm.{bias, weight}\n",
            "roi_heads.res5.0.conv3.weight\n",
            "roi_heads.res5.0.shortcut.norm.{bias, weight}\n",
            "roi_heads.res5.0.shortcut.weight\n",
            "roi_heads.res5.1.conv1.norm.{bias, weight}\n",
            "roi_heads.res5.1.conv1.weight\n",
            "roi_heads.res5.1.conv2.norm.{bias, weight}\n",
            "roi_heads.res5.1.conv2.weight\n",
            "roi_heads.res5.1.conv3.norm.{bias, weight}\n",
            "roi_heads.res5.1.conv3.weight\n",
            "roi_heads.res5.2.conv1.norm.{bias, weight}\n",
            "roi_heads.res5.2.conv1.weight\n",
            "roi_heads.res5.2.conv2.norm.{bias, weight}\n",
            "roi_heads.res5.2.conv2.weight\n",
            "roi_heads.res5.2.conv3.norm.{bias, weight}\n",
            "roi_heads.res5.2.conv3.weight\n",
            "WARNING:fvcore.common.checkpoint:The checkpoint state_dict contains keys that are not used by the model:\n",
            "  backbone.fpn_lateral2.{bias, weight}\n",
            "  backbone.fpn_output2.{bias, weight}\n",
            "  backbone.fpn_lateral3.{bias, weight}\n",
            "  backbone.fpn_output3.{bias, weight}\n",
            "  backbone.fpn_lateral4.{bias, weight}\n",
            "  backbone.fpn_output4.{bias, weight}\n",
            "  backbone.fpn_lateral5.{bias, weight}\n",
            "  backbone.fpn_output5.{bias, weight}\n",
            "  backbone.bottom_up.stem.conv1.weight\n",
            "  backbone.bottom_up.stem.conv1.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res2.0.shortcut.weight\n",
            "  backbone.bottom_up.res2.0.shortcut.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res2.0.conv1.weight\n",
            "  backbone.bottom_up.res2.0.conv1.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res2.0.conv2.weight\n",
            "  backbone.bottom_up.res2.0.conv2.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res2.0.conv3.weight\n",
            "  backbone.bottom_up.res2.0.conv3.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res2.1.conv1.weight\n",
            "  backbone.bottom_up.res2.1.conv1.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res2.1.conv2.weight\n",
            "  backbone.bottom_up.res2.1.conv2.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res2.1.conv3.weight\n",
            "  backbone.bottom_up.res2.1.conv3.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res2.2.conv1.weight\n",
            "  backbone.bottom_up.res2.2.conv1.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res2.2.conv2.weight\n",
            "  backbone.bottom_up.res2.2.conv2.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res2.2.conv3.weight\n",
            "  backbone.bottom_up.res2.2.conv3.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res3.0.shortcut.weight\n",
            "  backbone.bottom_up.res3.0.shortcut.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res3.0.conv1.weight\n",
            "  backbone.bottom_up.res3.0.conv1.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res3.0.conv2.weight\n",
            "  backbone.bottom_up.res3.0.conv2.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res3.0.conv3.weight\n",
            "  backbone.bottom_up.res3.0.conv3.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res3.1.conv1.weight\n",
            "  backbone.bottom_up.res3.1.conv1.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res3.1.conv2.weight\n",
            "  backbone.bottom_up.res3.1.conv2.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res3.1.conv3.weight\n",
            "  backbone.bottom_up.res3.1.conv3.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res3.2.conv1.weight\n",
            "  backbone.bottom_up.res3.2.conv1.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res3.2.conv2.weight\n",
            "  backbone.bottom_up.res3.2.conv2.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res3.2.conv3.weight\n",
            "  backbone.bottom_up.res3.2.conv3.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res3.3.conv1.weight\n",
            "  backbone.bottom_up.res3.3.conv1.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res3.3.conv2.weight\n",
            "  backbone.bottom_up.res3.3.conv2.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res3.3.conv3.weight\n",
            "  backbone.bottom_up.res3.3.conv3.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.0.shortcut.weight\n",
            "  backbone.bottom_up.res4.0.shortcut.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.0.conv1.weight\n",
            "  backbone.bottom_up.res4.0.conv1.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.0.conv2.weight\n",
            "  backbone.bottom_up.res4.0.conv2.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.0.conv3.weight\n",
            "  backbone.bottom_up.res4.0.conv3.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.1.conv1.weight\n",
            "  backbone.bottom_up.res4.1.conv1.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.1.conv2.weight\n",
            "  backbone.bottom_up.res4.1.conv2.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.1.conv3.weight\n",
            "  backbone.bottom_up.res4.1.conv3.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.2.conv1.weight\n",
            "  backbone.bottom_up.res4.2.conv1.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.2.conv2.weight\n",
            "  backbone.bottom_up.res4.2.conv2.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.2.conv3.weight\n",
            "  backbone.bottom_up.res4.2.conv3.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.3.conv1.weight\n",
            "  backbone.bottom_up.res4.3.conv1.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.3.conv2.weight\n",
            "  backbone.bottom_up.res4.3.conv2.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.3.conv3.weight\n",
            "  backbone.bottom_up.res4.3.conv3.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.4.conv1.weight\n",
            "  backbone.bottom_up.res4.4.conv1.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.4.conv2.weight\n",
            "  backbone.bottom_up.res4.4.conv2.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.4.conv3.weight\n",
            "  backbone.bottom_up.res4.4.conv3.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.5.conv1.weight\n",
            "  backbone.bottom_up.res4.5.conv1.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.5.conv2.weight\n",
            "  backbone.bottom_up.res4.5.conv2.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res4.5.conv3.weight\n",
            "  backbone.bottom_up.res4.5.conv3.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res5.0.shortcut.weight\n",
            "  backbone.bottom_up.res5.0.shortcut.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res5.0.conv1.weight\n",
            "  backbone.bottom_up.res5.0.conv1.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res5.0.conv2.weight\n",
            "  backbone.bottom_up.res5.0.conv2.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res5.0.conv3.weight\n",
            "  backbone.bottom_up.res5.0.conv3.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res5.1.conv1.weight\n",
            "  backbone.bottom_up.res5.1.conv1.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res5.1.conv2.weight\n",
            "  backbone.bottom_up.res5.1.conv2.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res5.1.conv3.weight\n",
            "  backbone.bottom_up.res5.1.conv3.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res5.2.conv1.weight\n",
            "  backbone.bottom_up.res5.2.conv1.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res5.2.conv2.weight\n",
            "  backbone.bottom_up.res5.2.conv2.norm.{bias, running_mean, running_var, weight}\n",
            "  backbone.bottom_up.res5.2.conv3.weight\n",
            "  backbone.bottom_up.res5.2.conv3.norm.{bias, running_mean, running_var, weight}\n",
            "  roi_heads.box_head.fc1.{bias, weight}\n",
            "  roi_heads.box_head.fc2.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([], device='cuda:0', dtype=torch.int64)\n",
            "Boxes(tensor([], device='cuda:0', size=(0, 4)))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-98de25f18a24>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Mendapatkan metadata (kategori, warna, dsb.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetadataCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASETS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Labels:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthing_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/detectron2/data/catalog.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    129\u001b[0m             )\n\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;34mf\"Attribute '{key}' does not exist in the metadata of dataset '{self.name}': \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;34m\"metadata is empty.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Attribute 'thing_classes' does not exist in the metadata of dataset 'custom_dataset_val': metadata is empty."
          ]
        }
      ]
    }
  ]
}